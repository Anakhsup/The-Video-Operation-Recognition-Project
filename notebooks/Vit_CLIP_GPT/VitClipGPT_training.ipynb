{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6ff9e2",
   "metadata": {},
   "source": [
    "ViT для видеоэмбеддингов и их интерпретации.\n",
    "CLIP для одновременной работы с видео и текстовыми метками.\n",
    "LLM для интерпретации визуальных эмбеддингов и определения операций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8e7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoProcessor, CLIPModel, CLIPProcessor, GPT2Model, GPT2Tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a36aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = '/root/tatneft/datasets/violations_dataset/cuts1'\n",
    "LABELS_FILE = '/root/tatneft/datasets/violations_dataset/cuts1_train.txt'\n",
    "VAL_LABELS_FILE = '/root/tatneft/datasets/violations_dataset/cuts1_val.txt'\n",
    "FRAME_COUNT = 8\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53259948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels_file):\n",
    "    \"\"\"Reads video paths and labels from a file. Returns list of (video_file, label) tuples.\n",
    "    \n",
    "    Args:\n",
    "        labels_file: Text file with lines formatted 'video_path label'.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (str, int) with video paths and integer labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(labels_file, 'r') as f:\n",
    "        for line in f:\n",
    "            video_file, label = line.strip().split()\n",
    "            data.append((video_file, int(label)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c85c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for loading videos and corresponding labels.\"\"\"\n",
    "\n",
    "    def __init__(self, video_dir, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            video_dir: Directory containing video files\n",
    "            labels: List of (video_filename, label) tuples\n",
    "            transform: Optional transform to apply to video frames\n",
    "        \"\"\"\n",
    "        self.video_dir = video_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of videos in the dataset.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            tuple: (transformed_frames, label) for video at given index\n",
    "        \"\"\"\n",
    "        video_file, label = self.labels[idx]\n",
    "        video_path = os.path.join(self.video_dir, video_file)\n",
    "        frames = self._load_video(video_path)\n",
    "        frames = torch.stack([self.transform(frame) for frame in frames])\n",
    "        return frames, label\n",
    "\n",
    "    def _load_video(self, path):\n",
    "        \"\"\"\n",
    "        Loads and pads video frames to FRAME_COUNT.\n",
    "        Returns:\n",
    "            list: PIL Image objects of video frames\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frames = []\n",
    "        count = 0\n",
    "        while cap.isOpened() and count < FRAME_COUNT:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            frames.append(frame)\n",
    "            count += 1\n",
    "        cap.release()\n",
    "        while len(frames) < FRAME_COUNT:\n",
    "            frames.append(frames[-1])\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc702f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Defining ViT precessor and model\"\"\"\n",
    "\n",
    "vit_processor = AutoProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model = torch.hub.load('facebookresearch/dino:main', 'dino_vitb8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96342103",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defining CLIP precessor and model\"\"\"\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c9a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPTextVideoClassifier(nn.Module):\n",
    "    \"\"\"Classifier combining CLIP's text and video features for classification.\n",
    "    \n",
    "    Uses CLIP's text embeddings from multiple frames and classifies them using\n",
    "    a linear layer on top of averaged frame embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clip_model, num_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            clip_model: Pretrained CLIP model\n",
    "            num_classes: Number of output classes\n",
    "        \"\"\"\n",
    "        super(CLIPTextVideoClassifier, self).__init__()\n",
    "        self.clip_model = clip_model\n",
    "        text_embed_dim = clip_model.config.text_config.hidden_size\n",
    "        self.fc = nn.Linear(text_embed_dim, num_classes)\n",
    "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    def forward(self, frames, text_inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            frames: Input video frames tensor of shape \n",
    "                   (batch_size, num_frames, channels, height, width)\n",
    "            text_inputs: List of text prompts (one per video in batch)\n",
    "        \n",
    "        Returns:\n",
    "            logits: Classification logits of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        batch_size, num_frames, channels, height, width = frames.size()\n",
    "        frames_list = [frames[i, j] for i in range(batch_size) for j in range(num_frames)]\n",
    "        inputs = self.clip_processor(\n",
    "            images=frames_list,\n",
    "            text=text_inputs * num_frames,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).to(frames.device)\n",
    "        outputs = self.clip_model(**inputs)\n",
    "        text_embeds = outputs.text_embeds.view(batch_size, num_frames, -1).mean(dim=1)\n",
    "        return self.fc(text_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da2f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, save_dir=\"checkpoints\"):\n",
    "    \"\"\"Trains a model with validation and checkpoint saving.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimization algorithm\n",
    "        save_dir: Directory to save checkpoints (default: \"checkpoints\")\n",
    "    \n",
    "    Returns:\n",
    "        None (saves best model weights to disk)\n",
    "    \n",
    "    Behavior:\n",
    "        - Trains for EPOCHS iterations\n",
    "        - Validates after each epoch\n",
    "        - Saves best model based on validation F1 score\n",
    "        - Prints training/validation metrics\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    best_metric = -1  \n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train() \n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            text_inputs = [f\"Label: {label.item()}\" for label in labels]\n",
    "            outputs = model(inputs, text_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        val_loss, val_metrics = validate_model(model, val_loader, criterion)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}: Train Loss {epoch_loss/len(train_loader):.4f}, Val Loss {val_loss:.4f}\")\n",
    "        print(f\"Validation Metrics: Precision: {val_metrics['precision']:.4f}, Recall: {val_metrics['recall']:.4f}, F1: {val_metrics['f1']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "        current_metric = val_metrics['f1'] \n",
    "        if current_metric > best_metric:\n",
    "            best_metric = current_metric\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"best_model_epoch_{epoch+1}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f746255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion):\n",
    "    \"\"\"Evaluates model performance on validation data.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to evaluate\n",
    "        val_loader: DataLoader for validation data\n",
    "        criterion: Loss function\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (val_loss, metrics_dict) where metrics_dict contains:\n",
    "            - precision (weighted average)\n",
    "            - recall (weighted average)\n",
    "            - f1 (weighted average)\n",
    "            - accuracy\n",
    "    \n",
    "    Note:\n",
    "        Uses weighted averaging for multiclass metrics. Sets model to eval mode.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_metrics = {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            text_inputs = [f\"Label: {label.item()}\" for label in labels]\n",
    "            outputs = model(inputs, text_inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    val_metrics = {'precision': precision, 'recall': recall, 'f1': f1, 'accuracy': accuracy}\n",
    "    return val_loss / len(val_loader), val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445edf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading data\"\"\"\n",
    "\n",
    "train_labels = load_labels(LABELS_FILE)\n",
    "val_labels = load_labels(VAL_LABELS_FILE)\n",
    "\n",
    "train_dataset = VideoDataset(VIDEO_DIR, train_labels)\n",
    "val_dataset = VideoDataset(VIDEO_DIR, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7b9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defining learning data\"\"\"\n",
    "\n",
    "num_classes = len(set(label for _, label in train_labels))\n",
    "model = CLIPTextVideoClassifier(clip_model, num_classes).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "106eab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [01:54<00:00,  4.78s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss 2.4098, Val Loss 2.2957\n",
      "Validation Metrics: Precision: 0.3140, Recall: 0.4177, F1: 0.2998, Accuracy: 0.4177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:04<00:00,  5.17s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss 2.4086, Val Loss 2.2965\n",
      "Validation Metrics: Precision: 0.1001, Recall: 0.3165, F1: 0.1521, Accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:05<00:00,  5.25s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss 2.4159, Val Loss 2.3039\n",
      "Validation Metrics: Precision: 0.1001, Recall: 0.3165, F1: 0.1521, Accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:02<00:00,  5.10s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss 2.4119, Val Loss 2.3062\n",
      "Validation Metrics: Precision: 0.1001, Recall: 0.3165, F1: 0.1521, Accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:07<00:00,  5.31s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss 2.4114, Val Loss 2.3038\n",
      "Validation Metrics: Precision: 0.1001, Recall: 0.3165, F1: 0.1521, Accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:05<00:00,  5.25s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss 2.4138, Val Loss 2.3025\n",
      "Validation Metrics: Precision: 0.1001, Recall: 0.3165, F1: 0.1521, Accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:06<00:00,  5.25s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss 2.4125, Val Loss 2.2967\n",
      "Validation Metrics: Precision: 0.1001, Recall: 0.3165, F1: 0.1521, Accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:06<00:00,  5.28s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss 2.4045, Val Loss 2.2912\n",
      "Validation Metrics: Precision: 0.3155, Recall: 0.5063, F1: 0.3697, Accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:07<00:00,  5.32s/it]\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss 2.4079, Val Loss 2.2939\n",
      "Validation Metrics: Precision: 0.3155, Recall: 0.5063, F1: 0.3697, Accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:06<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss 2.4053, Val Loss 2.2841\n",
      "Validation Metrics: Precision: 0.3140, Recall: 0.4177, F1: 0.2998, Accuracy: 0.4177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training model\"\"\"\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9a463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1258518/2096554531.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('checkpoints/best_model_epoch_8.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/best_model_epoch_8.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4097722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "/opt/conda/envs/tatneft/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.291225266456604,\n",
       " {'precision': 0.31545107494474584,\n",
       "  'recall': 0.5063291139240507,\n",
       "  'f1': 0.3696777905638665,\n",
       "  'accuracy': 0.5063291139240507})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Best score\"\"\"\n",
    "\n",
    "validate_model(model, val_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatneft",
   "language": "python",
   "name": "tatneft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
