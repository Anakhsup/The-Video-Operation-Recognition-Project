{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ZdzLJVJMvPpt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdzLJVJMvPpt",
    "outputId": "ea7e4827-1642-43c7-a77c-bbbecfd19998"
   },
   "outputs": [],
   "source": [
    "# !pip install av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30afa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !realpath train_vid2seq_c.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RkVdgMkEOQTJ",
   "metadata": {
    "id": "RkVdgMkEOQTJ"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1yjaLqF5ODzm",
   "metadata": {
    "id": "1yjaLqF5ODzm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from functools import partial\n",
    "\n",
    "# __all__ = ['resnet50', 'resnet101', 'resnet152', 'resnet200']\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4)).zero_()\n",
    "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "        zero_pads = zero_pads.cuda()\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, head_conv=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if head_conv == 1:\n",
    "            self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm3d(planes)\n",
    "        elif head_conv == 3:\n",
    "            self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=(3, 1, 1), bias=False, padding=(1, 0, 0))\n",
    "            self.bn1 = nn.BatchNorm3d(planes)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported head_conv!\")\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes, planes, kernel_size=(1, 3, 3), stride=(1, stride, stride), padding=(0, 1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def get_fine_tuning_parameters(model, ft_begin_index):\n",
    "    if ft_begin_index == 0:\n",
    "        return model.parameters()\n",
    "\n",
    "    ft_module_names = []\n",
    "    for i in range(ft_begin_index, 5):\n",
    "        ft_module_names.append('layer{}'.format(i))\n",
    "    ft_module_names.append('fc')\n",
    "\n",
    "    parameters = []\n",
    "    for k, v in model.named_parameters():\n",
    "        for ft_module in ft_module_names:\n",
    "            if ft_module in k:\n",
    "                parameters.append({'params': v})\n",
    "                break\n",
    "        else:\n",
    "            parameters.append({'params': v, 'lr': 0.0})\n",
    "\n",
    "    return parameters\n",
    "\n",
    "class SlowFast(nn.Module):\n",
    "    def __init__(self, block=Bottleneck, layers=[3, 4, 6, 3], class_num=27, shortcut_type='B', dropout=0.5,\n",
    "                 alpha=8, beta=0.125):\n",
    "        super(SlowFast, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        self.fast_inplanes = int(64 * beta)\n",
    "        fast_inplanes = self.fast_inplanes\n",
    "        self.fast_conv1 = nn.Conv3d(3, fast_inplanes, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3),\n",
    "                                    bias=False)\n",
    "        self.fast_bn1 = nn.BatchNorm3d(8)\n",
    "        self.fast_relu = nn.ReLU(inplace=True)\n",
    "        self.fast_maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
    "        self.fast_res1 = self._make_layer_fast(block, 8, layers[0], shortcut_type, head_conv=3)\n",
    "        self.fast_res2 = self._make_layer_fast(\n",
    "            block, 16, layers[1], shortcut_type, stride=2, head_conv=3)\n",
    "        self.fast_res3 = self._make_layer_fast(\n",
    "            block, 32, layers[2], shortcut_type, stride=2, head_conv=3)\n",
    "        self.fast_res4 = self._make_layer_fast(\n",
    "            block, 64, layers[3], shortcut_type, stride=2, head_conv=3)\n",
    "\n",
    "        self.slow_inplanes = 64\n",
    "        slow_inplanes = self.slow_inplanes\n",
    "        self.slow_conv1 = nn.Conv3d(3, slow_inplanes, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3),\n",
    "                                    bias=False)\n",
    "        self.slow_bn1 = nn.BatchNorm3d(64)\n",
    "        self.slow_relu = nn.ReLU(inplace=True)\n",
    "        self.slow_maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
    "        self.slow_res1 = self._make_layer_slow(block, 64, layers[0], shortcut_type, head_conv=1)\n",
    "        self.slow_res2 = self._make_layer_slow(\n",
    "            block, 128, layers[1], shortcut_type, stride=2, head_conv=1)\n",
    "        self.slow_res3 = self._make_layer_slow(\n",
    "            block, 256, layers[2], shortcut_type, stride=2, head_conv=1)\n",
    "        self.slow_res4 = self._make_layer_slow(\n",
    "            block, 512, layers[3], shortcut_type, stride=2, head_conv=1)\n",
    "\n",
    "        self.Tconv1 = nn.Conv3d(8, 16, kernel_size=(5, 1, 1), stride=(alpha, 1, 1), padding=(2, 0, 0), bias=False)\n",
    "        self.Tconv2 = nn.Conv3d(32, 64, kernel_size=(5, 1, 1), stride=(alpha, 1, 1), padding=(2, 0, 0), bias=False)\n",
    "        self.Tconv3 = nn.Conv3d(64, 128, kernel_size=(5, 1, 1), stride=(alpha, 1, 1), padding=(2, 0, 0), bias=False)\n",
    "        self.Tconv4 = nn.Conv3d(128, 256, kernel_size=(5, 1, 1), stride=(alpha, 1, 1), padding=(2, 0, 0), bias=False)\n",
    "\n",
    "        self.dp = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.fast_inplanes + self.slow_inplanes, class_num)\n",
    "\n",
    "    def forward(self, input):\n",
    "        fast, Tc = self.FastPath(input[:, :, ::2, :, :])\n",
    "        slow = self.SlowPath(input[:, :, ::16, :, :], Tc)\n",
    "        x = torch.cat([slow, fast], dim=1)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def SlowPath(self, input, Tc):\n",
    "        x = self.slow_conv1(input)\n",
    "        x = self.slow_bn1(x)\n",
    "        x = self.slow_relu(x)\n",
    "        x = self.slow_maxpool(x)\n",
    "        x = torch.cat([x, Tc[0]], dim=1)\n",
    "        x = self.slow_res1(x)\n",
    "        x = torch.cat([x, Tc[1]], dim=1)\n",
    "        x = self.slow_res2(x)\n",
    "        x = torch.cat([x, Tc[2]], dim=1)\n",
    "        x = self.slow_res3(x)\n",
    "        x = torch.cat([x, Tc[3]], dim=1)\n",
    "        x = self.slow_res4(x)\n",
    "        x = nn.AdaptiveAvgPool3d(1)(x)\n",
    "        x = x.view(-1, x.size(1))\n",
    "        return x\n",
    "\n",
    "    def FastPath(self, input):\n",
    "        x = self.fast_conv1(input)\n",
    "        x = self.fast_bn1(x)\n",
    "        x = self.fast_relu(x)\n",
    "        x = self.fast_maxpool(x)\n",
    "        Tc1 = self.Tconv1(x)\n",
    "        x = self.fast_res1(x)\n",
    "        Tc2 = self.Tconv2(x)\n",
    "        x = self.fast_res2(x)\n",
    "        Tc3 = self.Tconv3(x)\n",
    "        x = self.fast_res3(x)\n",
    "        Tc4 = self.Tconv4(x)\n",
    "        x = self.fast_res4(x)\n",
    "        x = nn.AdaptiveAvgPool3d(1)(x)\n",
    "        x = x.view(-1, x.size(1))\n",
    "        return x, [Tc1, Tc2, Tc3, Tc4]\n",
    "\n",
    "    def _make_layer_fast(self, block, planes, blocks, shortcut_type, stride=1, head_conv=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.fast_inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.fast_inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=(1, stride, stride),\n",
    "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.fast_inplanes, planes, stride, downsample, head_conv=head_conv))\n",
    "        self.fast_inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.fast_inplanes, planes, head_conv=head_conv))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_layer_slow(self, block, planes, blocks, shortcut_type, stride=1, head_conv=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.slow_inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.slow_inplanes + self.slow_inplanes // self.alpha * 2,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=(1, stride, stride),\n",
    "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.slow_inplanes + self.slow_inplanes // self.alpha * 2, planes, stride, downsample,\n",
    "                            head_conv=head_conv))\n",
    "        self.slow_inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.slow_inplanes, planes, head_conv=head_conv))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = SlowFast(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = SlowFast(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = SlowFast(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = SlowFast(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MmrPHRFPOUxy",
   "metadata": {
    "id": "MmrPHRFPOUxy"
   },
   "source": [
    "Clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9mrP5Gt6OVsi",
   "metadata": {
    "id": "9mrP5Gt6OVsi"
   },
   "outputs": [],
   "source": [
    "class OneCycle(object):\n",
    "    def __init__(self, nb, max_lr, momentum_vals=(0.95, 0.85), prcnt= 10 , div=10):\n",
    "        self.nb = nb\n",
    "        self.div = div\n",
    "        self.step_len =  int(self.nb * (1- prcnt/100)/2)\n",
    "        self.high_lr = max_lr\n",
    "        self.low_mom = momentum_vals[1]\n",
    "        self.high_mom = momentum_vals[0]\n",
    "        self.prcnt = prcnt\n",
    "        self.iteration = 0\n",
    "        self.lrs = []\n",
    "        self.moms = []\n",
    "\n",
    "    def calc(self):\n",
    "        self.iteration += 1\n",
    "        lr = self.calc_lr()\n",
    "        mom = self.calc_mom()\n",
    "        return (lr, mom)\n",
    "\n",
    "    def calc_lr(self):\n",
    "        if self.iteration==self.nb:\n",
    "            self.iteration = 0\n",
    "            self.lrs.append(self.high_lr/self.div)\n",
    "            return self.high_lr/self.div\n",
    "        if self.iteration > 2 * self.step_len:\n",
    "            ratio = (self.iteration - 2 * self.step_len) / (self.nb - 2 * self.step_len)\n",
    "            lr = self.high_lr * ( 1 - 0.99 * ratio)/self.div\n",
    "        elif self.iteration > self.step_len:\n",
    "            ratio = 1- (self.iteration -self.step_len)/self.step_len\n",
    "            lr = self.high_lr * (1 + ratio * (self.div - 1)) / self.div\n",
    "        else :\n",
    "            ratio = self.iteration/self.step_len\n",
    "            lr = self.high_lr * (1 + ratio * (self.div - 1)) / self.div\n",
    "        self.lrs.append(lr)\n",
    "        return lr\n",
    "\n",
    "    def calc_mom(self):\n",
    "        if self.iteration==self.nb:\n",
    "            self.iteration = 0\n",
    "            self.moms.append(self.high_mom)\n",
    "            return self.high_mom\n",
    "        if self.iteration > 2 * self.step_len:\n",
    "            mom = self.high_mom\n",
    "        elif self.iteration > self.step_len:\n",
    "            ratio = (self.iteration -self.step_len)/self.step_len\n",
    "            mom = self.low_mom + ratio * (self.high_mom - self.low_mom)\n",
    "        else :\n",
    "            ratio = self.iteration/self.step_len\n",
    "            mom = self.high_mom - ratio * (self.high_mom - self.low_mom)\n",
    "        self.moms.append(mom)\n",
    "        return mom\n",
    "def update_lr(optimizer, lr):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr\n",
    "def update_mom(optimizer, mom):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['momentum'] = mom\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd69fd8b",
   "metadata": {
    "id": "cd69fd8b"
   },
   "outputs": [],
   "source": [
    "# pip install opencv-python==4.5.5.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9d4848",
   "metadata": {
    "id": "eb9d4848"
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a201f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8a201f9",
    "outputId": "3d56b23b-de93-408f-a43c-4dfc29f1a42e"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "r6BlG4IhKyAF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6BlG4IhKyAF",
    "outputId": "22b7eee8-5925-4447-fc7e-56fecc9295b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gas_analyzer', 'syringing', 'inspection', 'measure', 'pipe_work', 'HRW_work', 'pipe_up', 'pipe_down', 'cleaning', 'open_mouth', 'gaskets', 'spider_landing', 'unscrewing PCP', 'remove_PCP', 'unscrewing_PCP', 'crane_lowering', 'crane_lifting', 'PCP_roll', 'cross_rotation']\n",
      "Decoder: {'gas_analyzer': 0, 'syringing': 1, 'inspection': 2, 'measure': 3, 'pipe_work': 4, 'HRW_work': 5, 'pipe_up': 6, 'pipe_down': 7, 'cleaning': 8, 'open_mouth': 9, 'gaskets': 10, 'spider_landing': 11, 'unscrewing PCP': 12, 'remove_PCP': 13, 'unscrewing_PCP': 14, 'crane_lowering': 15, 'crane_lifting': 16, 'PCP_roll': 17, 'cross_rotation': 18}\n",
      "Encoder: {0: 'gas_analyzer', 1: 'syringing', 2: 'inspection', 3: 'measure', 4: 'pipe_work', 5: 'HRW_work', 6: 'pipe_up', 7: 'pipe_down', 8: 'cleaning', 9: 'open_mouth', 10: 'gaskets', 11: 'spider_landing', 12: 'unscrewing PCP', 13: 'remove_PCP', 14: 'unscrewing_PCP', 15: 'crane_lowering', 16: 'crane_lifting', 17: 'PCP_roll', 18: 'cross_rotation'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = '/root/tatneft/datasets/violations_dataset/cuts1_labels.txt'\n",
    "with open(data_path, 'r') as file:\n",
    "    classes = [line.strip() for line in file.readlines()]\n",
    "print(classes)\n",
    "\n",
    "decoder = {}\n",
    "for i in range(len(classes)):\n",
    "#     if str(i) not in {'0', '6', '7', '8', '9', '10', '13', '15', '17'}:\n",
    "    decoder[classes[i]] = i\n",
    "\n",
    "encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    encoder[i] = classes[i]\n",
    "\n",
    "print(\"Decoder:\", decoder)\n",
    "print(\"Encoder:\", encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7350bd99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7350bd99",
    "outputId": "c5b9cd90-0b66-4628-b5d9-21c1092a7c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "[('ch03_20231002080000_cut_000041_000046.mp4', 0), ('ch03_20231002080000_cut_000046_000051.mp4', 0), ('ch03_20231002080000_cut_000136_000141.mp4', 0), ('ch03_20231002080000_cut_000141_000146.mp4', 0), ('ch03_20231002080000_cut_000221_000226.mp4', 0)]\n"
     ]
    }
   ],
   "source": [
    "id = list()\n",
    "\n",
    "path = '/root/tatneft/datasets/violations_dataset/cuts1_train.txt'\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        video_path, class_label = line.strip().split()\n",
    "        id.append((video_path, int(class_label)))\n",
    "\n",
    "print(len(id))\n",
    "print(id[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b1b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class video_dataset(Dataset):\n",
    "    def __init__(self, frame_list, sequence_length=16, transform=None, im_size=256):\n",
    "        self.frame_list = frame_list\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.im_size = im_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.frame_list[idx]\n",
    "        path = '/root/tatneft/datasets/violations_dataset/cuts1/' + path\n",
    "\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Не удалось открыть видео по пути: {path}\")\n",
    "\n",
    "        frames = []\n",
    "        while len(frames) < self.sequence_length:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        while len(frames) < self.sequence_length:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        seq_image = torch.stack(frames)  #форма: (sequence_length, channels, height, width)\n",
    "        seq_image = seq_image.permute(1, 0, 2, 3)  #меняем порядок осей: (channels, sequence_length, height, width)\n",
    "\n",
    "        return seq_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f436a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6f436a2",
    "outputId": "4c023790-c064-4e80-ba8c-155aac88b86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val'])\n"
     ]
    }
   ],
   "source": [
    "im_size = 128\n",
    "mean = [0.4889, 0.4887, 0.4891]\n",
    "std = [0.2074, 0.2074, 0.2074]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.RandomRotation(degrees=10),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "train_data = video_dataset(id,sequence_length = 10,transform = train_transforms)\n",
    "train_loader = DataLoader(train_data,batch_size = 8,num_workers = 1 ,shuffle = True)\n",
    "\n",
    "\n",
    "val_path = '/root/tatneft/datasets/violations_dataset/cuts1_val.txt'\n",
    "val_id = []\n",
    "with open(val_path, 'r') as file:\n",
    "    for line in file:\n",
    "        video_path, class_label = line.strip().split()\n",
    "        val_id.append((video_path, int(class_label)))\n",
    "\n",
    "val_data = video_dataset(val_id, sequence_length=10, transform=train_transforms)\n",
    "val_loader = DataLoader(val_data, batch_size=8, num_workers=1, shuffle=False)\n",
    "dataloaders = {'train':train_loader, 'val':val_loader}\n",
    "print(dataloaders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db7609be",
   "metadata": {
    "id": "db7609be"
   },
   "outputs": [],
   "source": [
    "model = resnet200(class_num=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faada049",
   "metadata": {
    "id": "faada049"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cls_criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9,weight_decay = 1e-4)\n",
    "num_epochs = 20\n",
    "onecyc = OneCycle(len(train_loader)*num_epochs,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d8c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# def calculate_metrics(outputs, labels):\n",
    "#     _, preds = torch.max(outputs, 1)\n",
    "#     accuracy = torch.sum(preds == labels).item() / len(labels)\n",
    "#     f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "#     return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6952d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #НЕ ТО\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# def train_model(model, train_loader, val_loader, cls_criterion, optimizer, num_epochs, device):\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_f1 = 0.0\n",
    "    \n",
    "#     all_labels = []\n",
    "#     all_preds = []\n",
    "    \n",
    "#     train_loss_graph = []\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'\\n--- Epoch {epoch+1}/{num_epochs} ---')\n",
    "\n",
    "#         model.train()\n",
    "#         train_running_loss = 0.0\n",
    "#         train_running_corrects = 0\n",
    "#         train_labels = []\n",
    "#         train_preds = []\n",
    "\n",
    "#         for inputs, labels in tqdm(train_loader):\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss = cls_criterion(outputs, labels)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             train_running_loss += loss.item() * inputs.size(0)\n",
    "#             train_running_corrects += torch.sum(preds == labels.data)\n",
    "#             train_labels.extend(labels.cpu().numpy())\n",
    "#             train_preds.extend(preds.cpu().numpy())\n",
    "            \n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "#         train_epoch_loss = train_running_loss / len(train_loader.dataset)\n",
    "#         train_loss_graph.append(train_epoch_loss)\n",
    "#         train_epoch_acc = train_running_corrects.double() / len(train_loader.dataset)\n",
    "#         train_epoch_f1 = f1_score(train_labels, train_preds, average='weighted')\n",
    "#         train_epoch_prec = precision_score(train_labels, train_preds, average='weighted', zero_division = np.nan)\n",
    "#         train_epoch_rec = recall_score(train_labels, train_preds, average='weighted')\n",
    "\n",
    "# #         print(f'Train Loss: {train_epoch_loss:.4f} Prec: {train_epoch_prec:.4f} Rec: {train_epoch_rec:.4f} Acc: {train_epoch_acc:.4f} F1: {train_epoch_f1:.4f}')\n",
    "# #         print(f'Train Loss: {train_epoch_loss:.4f}')\n",
    "\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_labels = []\n",
    "#         val_preds = []\n",
    "#         val_loss_graph = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in tqdm(val_loader):\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 loss = cls_criterion(outputs, labels)\n",
    "\n",
    "#                 val_running_loss += loss.item() * inputs.size(0)\n",
    "#                 val_running_corrects += torch.sum(preds == labels.data)\n",
    "#                 val_labels.extend(labels.cpu().numpy())\n",
    "#                 val_preds.extend(preds.cpu().numpy())\n",
    "                \n",
    "#                 all_labels.extend(labels.cpu().numpy())\n",
    "#                 all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "#         val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "#         val_loss_graph.append(val_epoch_loss)\n",
    "# #         val_epoch_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "# #         val_epoch_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "# #         val_epoch_prec = precision_score(val_labels, val_preds, average='weighted', zero_division = np.nan)\n",
    "# #         val_epoch_rec = recall_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "# #         print(f'Val Loss: {val_epoch_loss:.4f} Prec: {val_epoch_prec:.4f} Rec: {val_epoch_rec:.4f} Acc: {val_epoch_acc:.4f} F1: {val_epoch_f1:.4f}\\n')\n",
    "# #         print(f'Val Loss: {val_epoch_loss:.4f})\n",
    "    \n",
    "#         print(f'-------------------------------Total_{epoch+1}-------------------------------')\n",
    "#         all_epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "#         all_epoch_prec = precision_score(all_labels, all_preds, average='weighted', zero_division = np.nan) #исключены то, где нет результата\n",
    "#         all_epoch_rec = recall_score(all_labels, all_preds, average='weighted')\n",
    "#         all_epoch_ac = accuracy_score(all_labels, all_preds)\n",
    "#         print(f'Train Loss: {train_epoch_loss:.4f} Val Loss: {val_epoch_loss:.4f}\\n Prec: {all_epoch_prec:.4f} Rec: {all_epoch_rec:.4f} Acc: {all_epoch_ac:.4f} F1: {all_epoch_f1:.4f}\\n')\n",
    "        \n",
    "#         if all_epoch_f1 > best_f1:\n",
    "#             best_f1 = all_epoch_f1\n",
    "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             torch.save({\n",
    "#               'model_state_dict': model.state_dict(best_model_wts),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             }, f'/root/akhsup/res/model_v2s_{val_running_loss / len(val_loader.dataset):.4f}.pth')\n",
    "\n",
    "#     print(f'Best F1: {best_f1:.4f}')\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58baf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:37<00:00,  2.03s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.99s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_1-------------------------------\n",
      "Train Loss: 3.2563 Val Loss: 2.8685\n",
      " Prec: 0.1961 Rec: 0.2473 Acc: 0.2473 F1: 0.1955\n",
      "\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:41<00:00,  2.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:23<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_2-------------------------------\n",
      "Train Loss: 3.2444 Val Loss: 2.5187\n",
      " Prec: 0.1786 Rec: 0.2352 Acc: 0.2352 F1: 0.1929\n",
      "\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:34<00:00,  1.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_3-------------------------------\n",
      "Train Loss: 2.8907 Val Loss: 3.2633\n",
      " Prec: 0.1791 Rec: 0.2305 Acc: 0.2305 F1: 0.1903\n",
      "\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:32<00:00,  1.92s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_4-------------------------------\n",
      "Train Loss: 2.6592 Val Loss: 3.5958\n",
      " Prec: 0.1798 Rec: 0.2380 Acc: 0.2380 F1: 0.1935\n",
      "\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:36<00:00,  2.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_5-------------------------------\n",
      "Train Loss: 2.8406 Val Loss: 2.1324\n",
      " Prec: 0.1818 Rec: 0.2389 Acc: 0.2389 F1: 0.1946\n",
      "\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:41<00:00,  2.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.97s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_6-------------------------------\n",
      "Train Loss: 2.6460 Val Loss: 2.4503\n",
      " Prec: 0.1829 Rec: 0.2414 Acc: 0.2414 F1: 0.1964\n",
      "\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:35<00:00,  2.00s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.98s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_7-------------------------------\n",
      "Train Loss: 2.6373 Val Loss: 2.6161\n",
      " Prec: 0.1853 Rec: 0.2451 Acc: 0.2451 F1: 0.1995\n",
      "\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:54<00:00,  2.38s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.02s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_8-------------------------------\n",
      "Train Loss: 2.6036 Val Loss: 3.3128\n",
      " Prec: 0.1960 Rec: 0.2492 Acc: 0.2492 F1: 0.2046\n",
      "\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:35<00:00,  1.99s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.94s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_9-------------------------------\n",
      "Train Loss: 2.4297 Val Loss: 2.6418\n",
      " Prec: 0.2031 Rec: 0.2563 Acc: 0.2563 F1: 0.2112\n",
      "\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:42<00:00,  2.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.92s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_10-------------------------------\n",
      "Train Loss: 2.2737 Val Loss: 2.4360\n",
      " Prec: 0.2114 Rec: 0.2652 Acc: 0.2652 F1: 0.2194\n",
      "\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:32<00:00,  1.92s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.99s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_11-------------------------------\n",
      "Train Loss: 2.2582 Val Loss: 2.0408\n",
      " Prec: 0.2177 Rec: 0.2725 Acc: 0.2725 F1: 0.2260\n",
      "\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:34<00:00,  1.97s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.98s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_12-------------------------------\n",
      "Train Loss: 2.1345 Val Loss: 2.1601\n",
      " Prec: 0.2232 Rec: 0.2774 Acc: 0.2774 F1: 0.2314\n",
      "\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:47<00:00,  2.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.94s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_13-------------------------------\n",
      "Train Loss: 2.2249 Val Loss: 1.8783\n",
      " Prec: 0.2267 Rec: 0.2840 Acc: 0.2840 F1: 0.2378\n",
      "\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:32<00:00,  1.93s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.98s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_14-------------------------------\n",
      "Train Loss: 2.0931 Val Loss: 1.8134\n",
      " Prec: 0.2322 Rec: 0.2909 Acc: 0.2909 F1: 0.2437\n",
      "\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:39<00:00,  2.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.95s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_15-------------------------------\n",
      "Train Loss: 2.2516 Val Loss: 2.2375\n",
      " Prec: 0.2358 Rec: 0.2944 Acc: 0.2944 F1: 0.2473\n",
      "\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:34<00:00,  1.96s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_16-------------------------------\n",
      "Train Loss: 2.0716 Val Loss: 2.2449\n",
      " Prec: 0.2386 Rec: 0.2980 Acc: 0.2980 F1: 0.2502\n",
      "\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:32<00:00,  1.93s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.97s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_17-------------------------------\n",
      "Train Loss: 2.0082 Val Loss: 4.3608\n",
      " Prec: 0.2420 Rec: 0.3018 Acc: 0.3018 F1: 0.2546\n",
      "\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:32<00:00,  1.93s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.95s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_18-------------------------------\n",
      "Train Loss: 1.9945 Val Loss: 2.2032\n",
      " Prec: 0.2471 Rec: 0.3074 Acc: 0.3074 F1: 0.2599\n",
      "\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:33<00:00,  1.95s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.99s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_19-------------------------------\n",
      "Train Loss: 1.9692 Val Loss: 1.7219\n",
      " Prec: 0.2524 Rec: 0.3145 Acc: 0.3145 F1: 0.2664\n",
      "\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [01:35<00:00,  2.00s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/it]\n",
      "/tmp/ipykernel_3375799/1369666589.py:98: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  'model_state_dict': model.state_dict(best_model_wts),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Total_20-------------------------------\n",
      "Train Loss: 2.0408 Val Loss: 1.5724\n",
      " Prec: 0.2575 Rec: 0.3205 Acc: 0.3205 F1: 0.2723\n",
      "\n",
      "Best F1: 0.2723\n"
     ]
    }
   ],
   "source": [
    "# model = model.to(device)\n",
    "# model = train_model(model, train_loader, val_loader, cls_criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "032f4998",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_loss_graph\u001b[49m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_loss_graph, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_loss_graph, label = \"train loss\", color = \"blue\")\n",
    "# plt.plot(val_loss_graph, label = \"val loss\", color = \"black\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7732a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 0/48] [Loss: 2.696796 (2.696796), Acc: 12.50% (12.50%)]Min label: 1\n",
      "Max label: 9\n",
      "\\r[Epoch 0/20] [Batch 1/48] [Loss: 3.601731 (3.149264), Acc: 0.00% (6.25%)]Min label: 0\n",
      "Max label: 13\n",
      "\\r[Epoch 0/20] [Batch 2/48] [Loss: 3.097253 (3.131927), Acc: 12.50% (8.33%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 0/20] [Batch 3/48] [Loss: 3.050470 (3.111563), Acc: 0.00% (6.25%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 0/20] [Batch 4/48] [Loss: 3.228483 (3.134947), Acc: 12.50% (7.50%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 5/48] [Loss: 3.551912 (3.204441), Acc: 0.00% (6.25%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 0/20] [Batch 6/48] [Loss: 2.968245 (3.170699), Acc: 12.50% (7.14%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 0/20] [Batch 7/48] [Loss: 2.790424 (3.123164), Acc: 12.50% (7.81%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 0/20] [Batch 8/48] [Loss: 2.792476 (3.086421), Acc: 0.00% (6.94%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 9/48] [Loss: 2.424004 (3.020180), Acc: 25.00% (8.75%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 0/20] [Batch 10/48] [Loss: 2.453647 (2.968677), Acc: 12.50% (9.09%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 0/20] [Batch 11/48] [Loss: 2.444886 (2.925027), Acc: 25.00% (10.42%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 0/20] [Batch 12/48] [Loss: 2.726114 (2.909726), Acc: 37.50% (12.50%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 13/48] [Loss: 1.794878 (2.830094), Acc: 50.00% (15.18%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 0/20] [Batch 14/48] [Loss: 2.813254 (2.828972), Acc: 12.50% (15.00%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 0/20] [Batch 15/48] [Loss: 1.556842 (2.749464), Acc: 50.00% (17.19%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 16/48] [Loss: 3.837832 (2.813485), Acc: 12.50% (16.91%)]Min label: 3\n",
      "Max label: 7\n",
      "\\r[Epoch 0/20] [Batch 17/48] [Loss: 3.158114 (2.832631), Acc: 12.50% (16.67%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 18/48] [Loss: 4.607912 (2.926067), Acc: 0.00% (15.79%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 0/20] [Batch 19/48] [Loss: 2.045811 (2.882054), Acc: 62.50% (18.12%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 0/20] [Batch 20/48] [Loss: 3.301327 (2.902020), Acc: 37.50% (19.05%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 21/48] [Loss: 3.066346 (2.909489), Acc: 25.00% (19.32%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 0/20] [Batch 22/48] [Loss: 2.858043 (2.907252), Acc: 12.50% (19.02%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 0/20] [Batch 23/48] [Loss: 2.975041 (2.910077), Acc: 25.00% (19.27%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 24/48] [Loss: 1.896159 (2.869520), Acc: 50.00% (20.50%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 25/48] [Loss: 3.079451 (2.877594), Acc: 25.00% (20.67%)]Min label: 3\n",
      "Max label: 17\n",
      "\\r[Epoch 0/20] [Batch 26/48] [Loss: 4.938368 (2.953919), Acc: 0.00% (19.91%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 0/20] [Batch 27/48] [Loss: 3.910308 (2.988076), Acc: 12.50% (19.64%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 28/48] [Loss: 3.288647 (2.998441), Acc: 25.00% (19.83%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 29/48] [Loss: 4.275858 (3.041021), Acc: 0.00% (19.17%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 0/20] [Batch 30/48] [Loss: 2.320350 (3.017774), Acc: 25.00% (19.35%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 31/48] [Loss: 3.301214 (3.026631), Acc: 0.00% (18.75%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 32/48] [Loss: 2.223265 (3.002287), Acc: 12.50% (18.56%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 0/20] [Batch 33/48] [Loss: 2.439865 (2.985745), Acc: 25.00% (18.75%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 34/48] [Loss: 3.183314 (2.991390), Acc: 25.00% (18.93%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 0/20] [Batch 35/48] [Loss: 2.408574 (2.975200), Acc: 12.50% (18.75%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 36/48] [Loss: 3.102598 (2.978644), Acc: 0.00% (18.24%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 37/48] [Loss: 2.850047 (2.975259), Acc: 12.50% (18.09%)]Min label: 1\n",
      "Max label: 4\n",
      "\\r[Epoch 0/20] [Batch 38/48] [Loss: 2.440336 (2.961543), Acc: 25.00% (18.27%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 39/48] [Loss: 3.815260 (2.982886), Acc: 12.50% (18.12%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 0/20] [Batch 40/48] [Loss: 2.615890 (2.973935), Acc: 25.00% (18.29%)]Min label: 1\n",
      "Max label: 10\n",
      "\\r[Epoch 0/20] [Batch 41/48] [Loss: 2.647595 (2.966165), Acc: 37.50% (18.75%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 0/20] [Batch 42/48] [Loss: 1.796670 (2.938968), Acc: 50.00% (19.48%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 0/20] [Batch 43/48] [Loss: 2.462162 (2.928131), Acc: 25.00% (19.60%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 0/20] [Batch 44/48] [Loss: 2.220065 (2.912396), Acc: 62.50% (20.56%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 0/20] [Batch 45/48] [Loss: 3.755084 (2.930716), Acc: 12.50% (20.38%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 0/20] [Batch 46/48] [Loss: 2.767349 (2.927240), Acc: 25.00% (20.48%)]Min label: 4\n",
      "Max label: 5\n",
      "\\r[Epoch 0/20] [Batch 47/48] [Loss: 3.246782 (2.933897), Acc: 50.00% (21.09%)]\n",
      "train , acc: 21.09375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:45<00:00, 105.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 1/20] [Batch 0/48] [Loss: 2.273354 (2.273354), Acc: 37.50% (37.50%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 1/48] [Loss: 2.589894 (2.431624), Acc: 25.00% (31.25%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 1/20] [Batch 2/48] [Loss: 4.112683 (2.991977), Acc: 12.50% (25.00%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 3/48] [Loss: 2.684614 (2.915136), Acc: 25.00% (25.00%)]Min label: 0\n",
      "Max label: 6\n",
      "\\r[Epoch 1/20] [Batch 4/48] [Loss: 2.184447 (2.768998), Acc: 25.00% (25.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 5/48] [Loss: 3.752126 (2.932853), Acc: 0.00% (20.83%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 6/48] [Loss: 2.684476 (2.897370), Acc: 37.50% (23.21%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 1/20] [Batch 7/48] [Loss: 2.707988 (2.873698), Acc: 25.00% (23.44%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 1/20] [Batch 8/48] [Loss: 2.798624 (2.865356), Acc: 37.50% (25.00%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 1/20] [Batch 9/48] [Loss: 3.127001 (2.891521), Acc: 25.00% (25.00%)]Min label: 3\n",
      "Max label: 17\n",
      "\\r[Epoch 1/20] [Batch 10/48] [Loss: 2.737591 (2.877527), Acc: 0.00% (22.73%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 11/48] [Loss: 2.533301 (2.848842), Acc: 0.00% (20.83%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 12/48] [Loss: 3.143790 (2.871530), Acc: 0.00% (19.23%)]Min label: 2\n",
      "Max label: 8\n",
      "\\r[Epoch 1/20] [Batch 13/48] [Loss: 3.039089 (2.883498), Acc: 12.50% (18.75%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 1/20] [Batch 14/48] [Loss: 2.337322 (2.847087), Acc: 37.50% (20.00%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 15/48] [Loss: 2.409676 (2.819748), Acc: 25.00% (20.31%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 1/20] [Batch 16/48] [Loss: 2.405591 (2.795386), Acc: 25.00% (20.59%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 17/48] [Loss: 2.292924 (2.767472), Acc: 12.50% (20.14%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 1/20] [Batch 18/48] [Loss: 2.077952 (2.731181), Acc: 25.00% (20.39%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 1/20] [Batch 19/48] [Loss: 2.489083 (2.719076), Acc: 12.50% (20.00%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 1/20] [Batch 20/48] [Loss: 2.237742 (2.696156), Acc: 25.00% (20.24%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 21/48] [Loss: 2.253757 (2.676047), Acc: 0.00% (19.32%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 1/20] [Batch 22/48] [Loss: 2.190080 (2.654918), Acc: 25.00% (19.57%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 1/20] [Batch 23/48] [Loss: 2.803685 (2.661116), Acc: 25.00% (19.79%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 1/20] [Batch 24/48] [Loss: 2.609863 (2.659066), Acc: 0.00% (19.00%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 1/20] [Batch 25/48] [Loss: 2.350741 (2.647207), Acc: 25.00% (19.23%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 26/48] [Loss: 3.001072 (2.660314), Acc: 25.00% (19.44%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 1/20] [Batch 27/48] [Loss: 1.776067 (2.628733), Acc: 25.00% (19.64%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 1/20] [Batch 28/48] [Loss: 3.297966 (2.651810), Acc: 25.00% (19.83%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 29/48] [Loss: 4.214524 (2.703901), Acc: 12.50% (19.58%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 30/48] [Loss: 3.154877 (2.718448), Acc: 12.50% (19.35%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 1/20] [Batch 31/48] [Loss: 2.965180 (2.726159), Acc: 25.00% (19.53%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 1/20] [Batch 32/48] [Loss: 2.233025 (2.711215), Acc: 37.50% (20.08%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 33/48] [Loss: 2.857859 (2.715528), Acc: 12.50% (19.85%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 1/20] [Batch 34/48] [Loss: 2.678901 (2.714482), Acc: 12.50% (19.64%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 1/20] [Batch 35/48] [Loss: 2.038872 (2.695715), Acc: 12.50% (19.44%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 36/48] [Loss: 2.121513 (2.680196), Acc: 50.00% (20.27%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 1/20] [Batch 37/48] [Loss: 1.969742 (2.661500), Acc: 12.50% (20.07%)]Min label: 3\n",
      "Max label: 13\n",
      "\\r[Epoch 1/20] [Batch 38/48] [Loss: 2.805399 (2.665190), Acc: 12.50% (19.87%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 39/48] [Loss: 3.258380 (2.680019), Acc: 12.50% (19.69%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 1/20] [Batch 40/48] [Loss: 2.074119 (2.665241), Acc: 25.00% (19.82%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 41/48] [Loss: 2.205133 (2.654286), Acc: 37.50% (20.24%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 42/48] [Loss: 2.833240 (2.658448), Acc: 12.50% (20.06%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 1/20] [Batch 43/48] [Loss: 2.109401 (2.645970), Acc: 50.00% (20.74%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 1/20] [Batch 44/48] [Loss: 3.133307 (2.656799), Acc: 12.50% (20.56%)]Min label: 0\n",
      "Max label: 7\n",
      "\\r[Epoch 1/20] [Batch 45/48] [Loss: 1.940941 (2.641237), Acc: 37.50% (20.92%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 1/20] [Batch 46/48] [Loss: 2.254912 (2.633018), Acc: 25.00% (21.01%)]Min label: 3\n",
      "Max label: 4\n",
      "\\r[Epoch 1/20] [Batch 47/48] [Loss: 1.697967 (2.613537), Acc: 50.00% (21.61%)]\n",
      "train , acc: 21.614583333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:47<00:00, 107.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 0/48] [Loss: 2.541236 (2.541236), Acc: 12.50% (12.50%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 1/48] [Loss: 2.316710 (2.428973), Acc: 25.00% (18.75%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 2/20] [Batch 2/48] [Loss: 2.342279 (2.400075), Acc: 12.50% (16.67%)]Min label: 2\n",
      "Max label: 6\n",
      "\\r[Epoch 2/20] [Batch 3/48] [Loss: 2.531809 (2.433009), Acc: 37.50% (21.88%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 2/20] [Batch 4/48] [Loss: 2.373944 (2.421196), Acc: 25.00% (22.50%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 2/20] [Batch 5/48] [Loss: 3.037047 (2.523838), Acc: 37.50% (25.00%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 6/48] [Loss: 1.763676 (2.415243), Acc: 12.50% (23.21%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 7/48] [Loss: 1.933906 (2.355076), Acc: 37.50% (25.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 8/48] [Loss: 2.657618 (2.388692), Acc: 12.50% (23.61%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 2/20] [Batch 9/48] [Loss: 3.362499 (2.486072), Acc: 12.50% (22.50%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 10/48] [Loss: 3.004403 (2.533193), Acc: 25.00% (22.73%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 2/20] [Batch 11/48] [Loss: 2.944889 (2.567501), Acc: 25.00% (22.92%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 12/48] [Loss: 1.814139 (2.509550), Acc: 50.00% (25.00%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 2/20] [Batch 13/48] [Loss: 2.555561 (2.512837), Acc: 50.00% (26.79%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 2/20] [Batch 14/48] [Loss: 2.879460 (2.537278), Acc: 12.50% (25.83%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 15/48] [Loss: 1.897481 (2.497291), Acc: 37.50% (26.56%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 16/48] [Loss: 2.531324 (2.499293), Acc: 25.00% (26.47%)]Min label: 2\n",
      "Max label: 7\n",
      "\\r[Epoch 2/20] [Batch 17/48] [Loss: 2.265397 (2.486299), Acc: 25.00% (26.39%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 2/20] [Batch 18/48] [Loss: 2.435902 (2.483646), Acc: 25.00% (26.32%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 2/20] [Batch 19/48] [Loss: 1.890635 (2.453996), Acc: 50.00% (27.50%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 2/20] [Batch 20/48] [Loss: 2.410412 (2.451920), Acc: 25.00% (27.38%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 2/20] [Batch 21/48] [Loss: 2.765690 (2.466183), Acc: 25.00% (27.27%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 2/20] [Batch 22/48] [Loss: 3.765131 (2.522659), Acc: 25.00% (27.17%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 23/48] [Loss: 3.473444 (2.562275), Acc: 12.50% (26.56%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 2/20] [Batch 24/48] [Loss: 2.512590 (2.560287), Acc: 25.00% (26.50%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 2/20] [Batch 25/48] [Loss: 2.711127 (2.566089), Acc: 12.50% (25.96%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 26/48] [Loss: 2.494087 (2.563422), Acc: 25.00% (25.93%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 27/48] [Loss: 1.965353 (2.542062), Acc: 25.00% (25.89%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 2/20] [Batch 28/48] [Loss: 1.839461 (2.517835), Acc: 50.00% (26.72%)]Min label: 3\n",
      "Max label: 17\n",
      "\\r[Epoch 2/20] [Batch 29/48] [Loss: 3.735635 (2.558428), Acc: 37.50% (27.08%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 30/48] [Loss: 2.383973 (2.552801), Acc: 25.00% (27.02%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 2/20] [Batch 31/48] [Loss: 3.093234 (2.569689), Acc: 25.00% (26.95%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 2/20] [Batch 32/48] [Loss: 2.784689 (2.576204), Acc: 12.50% (26.52%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 33/48] [Loss: 2.386648 (2.570629), Acc: 25.00% (26.47%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 2/20] [Batch 34/48] [Loss: 1.719439 (2.546309), Acc: 37.50% (26.79%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 2/20] [Batch 35/48] [Loss: 2.059497 (2.532787), Acc: 50.00% (27.43%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 2/20] [Batch 36/48] [Loss: 2.580214 (2.534069), Acc: 37.50% (27.70%)]Min label: 3\n",
      "Max label: 6\n",
      "\\r[Epoch 2/20] [Batch 37/48] [Loss: 1.787462 (2.514421), Acc: 37.50% (27.96%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 38/48] [Loss: 5.034961 (2.579050), Acc: 0.00% (27.24%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 2/20] [Batch 39/48] [Loss: 2.339704 (2.573067), Acc: 37.50% (27.50%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 40/48] [Loss: 3.239535 (2.589322), Acc: 12.50% (27.13%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 2/20] [Batch 41/48] [Loss: 2.661572 (2.591042), Acc: 0.00% (26.49%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 2/20] [Batch 42/48] [Loss: 2.874100 (2.597625), Acc: 25.00% (26.45%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 2/20] [Batch 43/48] [Loss: 2.522254 (2.595912), Acc: 12.50% (26.14%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 2/20] [Batch 44/48] [Loss: 2.773220 (2.599852), Acc: 12.50% (25.83%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 2/20] [Batch 45/48] [Loss: 2.722603 (2.602521), Acc: 12.50% (25.54%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 2/20] [Batch 46/48] [Loss: 2.557815 (2.601569), Acc: 25.00% (25.53%)]Min label: 3\n",
      "Max label: 4\n",
      "\\r[Epoch 2/20] [Batch 47/48] [Loss: 5.827247 (2.668771), Acc: 0.00% (25.00%)]\n",
      "train , acc: 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:49<00:00, 109.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 3/20] [Batch 0/48] [Loss: 2.765605 (2.765605), Acc: 37.50% (37.50%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 1/48] [Loss: 3.692962 (3.229283), Acc: 0.00% (18.75%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 3/20] [Batch 2/48] [Loss: 3.866565 (3.441710), Acc: 12.50% (16.67%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 3/48] [Loss: 2.522653 (3.211946), Acc: 25.00% (18.75%)]Min label: 4\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 4/48] [Loss: 3.293823 (3.228321), Acc: 25.00% (20.00%)]Min label: 0\n",
      "Max label: 8\n",
      "\\r[Epoch 3/20] [Batch 5/48] [Loss: 2.400167 (3.090296), Acc: 0.00% (16.67%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 3/20] [Batch 6/48] [Loss: 2.711093 (3.036124), Acc: 25.00% (17.86%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 3/20] [Batch 7/48] [Loss: 3.048850 (3.037715), Acc: 25.00% (18.75%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 3/20] [Batch 8/48] [Loss: 2.552564 (2.983809), Acc: 12.50% (18.06%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 3/20] [Batch 9/48] [Loss: 2.903766 (2.975805), Acc: 25.00% (18.75%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 3/20] [Batch 10/48] [Loss: 2.452649 (2.928245), Acc: 25.00% (19.32%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 3/20] [Batch 11/48] [Loss: 2.362788 (2.881124), Acc: 25.00% (19.79%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 12/48] [Loss: 3.589752 (2.935634), Acc: 12.50% (19.23%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 13/48] [Loss: 3.522172 (2.977529), Acc: 12.50% (18.75%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 14/48] [Loss: 2.607469 (2.952859), Acc: 0.00% (17.50%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 15/48] [Loss: 1.498815 (2.861981), Acc: 62.50% (20.31%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 3/20] [Batch 16/48] [Loss: 1.922953 (2.806744), Acc: 37.50% (21.32%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 3/20] [Batch 17/48] [Loss: 3.620019 (2.851926), Acc: 12.50% (20.83%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 3/20] [Batch 18/48] [Loss: 1.986185 (2.806361), Acc: 50.00% (22.37%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 19/48] [Loss: 3.197745 (2.825930), Acc: 25.00% (22.50%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 3/20] [Batch 20/48] [Loss: 2.087497 (2.790766), Acc: 12.50% (22.02%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 3/20] [Batch 21/48] [Loss: 2.466881 (2.776044), Acc: 25.00% (22.16%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 22/48] [Loss: 3.538936 (2.809213), Acc: 0.00% (21.20%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 3/20] [Batch 23/48] [Loss: 2.163262 (2.782299), Acc: 0.00% (20.31%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 3/20] [Batch 24/48] [Loss: 2.411932 (2.767484), Acc: 25.00% (20.50%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 3/20] [Batch 25/48] [Loss: 2.131332 (2.743017), Acc: 37.50% (21.15%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 3/20] [Batch 26/48] [Loss: 1.703352 (2.704511), Acc: 37.50% (21.76%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 27/48] [Loss: 2.186613 (2.686014), Acc: 37.50% (22.32%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 28/48] [Loss: 3.411631 (2.711036), Acc: 12.50% (21.98%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 29/48] [Loss: 2.356942 (2.699233), Acc: 37.50% (22.50%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 3/20] [Batch 30/48] [Loss: 1.814312 (2.670687), Acc: 37.50% (22.98%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 31/48] [Loss: 2.022609 (2.650434), Acc: 25.00% (23.05%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 32/48] [Loss: 1.809169 (2.624941), Acc: 37.50% (23.48%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 3/20] [Batch 33/48] [Loss: 1.978314 (2.605923), Acc: 25.00% (23.53%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 3/20] [Batch 34/48] [Loss: 1.326585 (2.569370), Acc: 50.00% (24.29%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 35/48] [Loss: 3.499996 (2.595221), Acc: 0.00% (23.61%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 3/20] [Batch 36/48] [Loss: 2.929115 (2.604245), Acc: 37.50% (23.99%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 3/20] [Batch 37/48] [Loss: 1.479716 (2.574652), Acc: 50.00% (24.67%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 3/20] [Batch 38/48] [Loss: 1.806178 (2.554948), Acc: 37.50% (25.00%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 39/48] [Loss: 2.269110 (2.547802), Acc: 25.00% (25.00%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 3/20] [Batch 40/48] [Loss: 1.803836 (2.529657), Acc: 25.00% (25.00%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 3/20] [Batch 41/48] [Loss: 2.112606 (2.519727), Acc: 25.00% (25.00%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 3/20] [Batch 42/48] [Loss: 3.627983 (2.545500), Acc: 12.50% (24.71%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 3/20] [Batch 43/48] [Loss: 1.706024 (2.526421), Acc: 37.50% (25.00%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 3/20] [Batch 44/48] [Loss: 2.047760 (2.515784), Acc: 12.50% (24.72%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 45/48] [Loss: 1.574115 (2.495313), Acc: 50.00% (25.27%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 3/20] [Batch 46/48] [Loss: 3.452801 (2.515685), Acc: 12.50% (25.00%)]Min label: 0\n",
      "Max label: 1\n",
      "\\r[Epoch 3/20] [Batch 47/48] [Loss: 2.647330 (2.518428), Acc: 50.00% (25.52%)]\n",
      "train , acc: 25.520833333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:41<00:00, 101.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 4/20] [Batch 0/48] [Loss: 2.446926 (2.446926), Acc: 25.00% (25.00%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 4/20] [Batch 1/48] [Loss: 1.171678 (1.809302), Acc: 37.50% (31.25%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 2/48] [Loss: 2.138039 (1.918881), Acc: 25.00% (29.17%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 4/20] [Batch 3/48] [Loss: 2.315251 (2.017974), Acc: 37.50% (31.25%)]Min label: 3\n",
      "Max label: 13\n",
      "\\r[Epoch 4/20] [Batch 4/48] [Loss: 2.741808 (2.162740), Acc: 50.00% (35.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 5/48] [Loss: 4.994988 (2.634782), Acc: 25.00% (33.33%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 6/48] [Loss: 3.866280 (2.810710), Acc: 25.00% (32.14%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 7/48] [Loss: 4.326708 (3.000210), Acc: 37.50% (32.81%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 8/48] [Loss: 2.874572 (2.986250), Acc: 25.00% (31.94%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 9/48] [Loss: 1.188734 (2.806498), Acc: 62.50% (35.00%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 10/48] [Loss: 2.167662 (2.748422), Acc: 37.50% (35.23%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 11/48] [Loss: 2.125595 (2.696520), Acc: 25.00% (34.38%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 4/20] [Batch 12/48] [Loss: 1.600007 (2.612173), Acc: 50.00% (35.58%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 13/48] [Loss: 2.662738 (2.615785), Acc: 37.50% (35.71%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 14/48] [Loss: 2.323976 (2.596331), Acc: 25.00% (35.00%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 15/48] [Loss: 2.189439 (2.570900), Acc: 25.00% (34.38%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 4/20] [Batch 16/48] [Loss: 2.476766 (2.565363), Acc: 0.00% (32.35%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 4/20] [Batch 17/48] [Loss: 2.557818 (2.564944), Acc: 12.50% (31.25%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 18/48] [Loss: 1.852218 (2.527432), Acc: 25.00% (30.92%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 19/48] [Loss: 2.658248 (2.533973), Acc: 0.00% (29.38%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 4/20] [Batch 20/48] [Loss: 1.963790 (2.506821), Acc: 25.00% (29.17%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 4/20] [Batch 21/48] [Loss: 2.162307 (2.491161), Acc: 25.00% (28.98%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 22/48] [Loss: 2.194696 (2.478271), Acc: 0.00% (27.72%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 4/20] [Batch 23/48] [Loss: 1.728487 (2.447030), Acc: 37.50% (28.12%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 24/48] [Loss: 1.848304 (2.423081), Acc: 37.50% (28.50%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 25/48] [Loss: 2.009587 (2.407178), Acc: 37.50% (28.85%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 26/48] [Loss: 2.221022 (2.400283), Acc: 37.50% (29.17%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 4/20] [Batch 27/48] [Loss: 4.126686 (2.461940), Acc: 37.50% (29.46%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 4/20] [Batch 28/48] [Loss: 3.761674 (2.506759), Acc: 25.00% (29.31%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 29/48] [Loss: 4.621578 (2.577253), Acc: 0.00% (28.33%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 30/48] [Loss: 3.086581 (2.593683), Acc: 25.00% (28.23%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 4/20] [Batch 31/48] [Loss: 1.009963 (2.544191), Acc: 75.00% (29.69%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 32/48] [Loss: 3.678867 (2.578576), Acc: 12.50% (29.17%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 33/48] [Loss: 2.158095 (2.566208), Acc: 25.00% (29.04%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 34/48] [Loss: 1.795594 (2.544191), Acc: 50.00% (29.64%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 4/20] [Batch 35/48] [Loss: 1.972863 (2.528321), Acc: 25.00% (29.51%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 36/48] [Loss: 3.323328 (2.549807), Acc: 25.00% (29.39%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 4/20] [Batch 37/48] [Loss: 1.962631 (2.534355), Acc: 37.50% (29.61%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 38/48] [Loss: 3.081791 (2.548392), Acc: 12.50% (29.17%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 39/48] [Loss: 2.532499 (2.547995), Acc: 12.50% (28.75%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 40/48] [Loss: 2.211643 (2.539791), Acc: 25.00% (28.66%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 41/48] [Loss: 1.595001 (2.517296), Acc: 37.50% (28.87%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 4/20] [Batch 42/48] [Loss: 3.171780 (2.532517), Acc: 0.00% (28.20%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 4/20] [Batch 43/48] [Loss: 1.710077 (2.513825), Acc: 50.00% (28.69%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 4/20] [Batch 44/48] [Loss: 2.270518 (2.508418), Acc: 12.50% (28.33%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 4/20] [Batch 45/48] [Loss: 1.640945 (2.489560), Acc: 50.00% (28.80%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 46/48] [Loss: 2.413155 (2.487934), Acc: 37.50% (28.99%)]Min label: 4\n",
      "Max label: 14\n",
      "\\r[Epoch 4/20] [Batch 47/48] [Loss: 2.185417 (2.481632), Acc: 0.00% (28.39%)]\n",
      "train , acc: 28.385416666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:46<00:00, 106.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 0/48] [Loss: 2.829048 (2.829048), Acc: 50.00% (50.00%)]Min label: 2\n",
      "Max label: 10\n",
      "\\r[Epoch 5/20] [Batch 1/48] [Loss: 2.624972 (2.727010), Acc: 50.00% (50.00%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 5/20] [Batch 2/48] [Loss: 2.187275 (2.547098), Acc: 37.50% (45.83%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 3/48] [Loss: 3.409727 (2.762755), Acc: 25.00% (40.62%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 5/20] [Batch 4/48] [Loss: 1.087055 (2.427615), Acc: 37.50% (40.00%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 5/48] [Loss: 2.284458 (2.403756), Acc: 12.50% (35.42%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 6/48] [Loss: 1.962964 (2.340785), Acc: 25.00% (33.93%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 5/20] [Batch 7/48] [Loss: 2.599252 (2.373094), Acc: 12.50% (31.25%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 5/20] [Batch 8/48] [Loss: 1.539473 (2.280469), Acc: 37.50% (31.94%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 9/48] [Loss: 2.360234 (2.288446), Acc: 25.00% (31.25%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 5/20] [Batch 10/48] [Loss: 1.996420 (2.261898), Acc: 25.00% (30.68%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 5/20] [Batch 11/48] [Loss: 2.301921 (2.265233), Acc: 25.00% (30.21%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 12/48] [Loss: 2.051193 (2.248769), Acc: 37.50% (30.77%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 5/20] [Batch 13/48] [Loss: 1.760491 (2.213892), Acc: 25.00% (30.36%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 5/20] [Batch 14/48] [Loss: 2.074217 (2.204580), Acc: 12.50% (29.17%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 5/20] [Batch 15/48] [Loss: 1.305931 (2.148414), Acc: 50.00% (30.47%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 5/20] [Batch 16/48] [Loss: 2.723859 (2.182264), Acc: 50.00% (31.62%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 5/20] [Batch 17/48] [Loss: 1.550727 (2.147179), Acc: 37.50% (31.94%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 5/20] [Batch 18/48] [Loss: 1.862141 (2.132177), Acc: 62.50% (33.55%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 19/48] [Loss: 1.948076 (2.122972), Acc: 12.50% (32.50%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 20/48] [Loss: 2.421968 (2.137210), Acc: 12.50% (31.55%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 21/48] [Loss: 2.058648 (2.133639), Acc: 25.00% (31.25%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 22/48] [Loss: 0.928143 (2.081226), Acc: 62.50% (32.61%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 5/20] [Batch 23/48] [Loss: 2.938589 (2.116949), Acc: 12.50% (31.77%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 24/48] [Loss: 2.527298 (2.133363), Acc: 12.50% (31.00%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 5/20] [Batch 25/48] [Loss: 1.152472 (2.095637), Acc: 50.00% (31.73%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 26/48] [Loss: 2.284211 (2.102621), Acc: 12.50% (31.02%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 27/48] [Loss: 2.117272 (2.103144), Acc: 0.00% (29.91%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 5/20] [Batch 28/48] [Loss: 1.880090 (2.095453), Acc: 62.50% (31.03%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 29/48] [Loss: 1.838366 (2.086883), Acc: 25.00% (30.83%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 5/20] [Batch 30/48] [Loss: 1.061978 (2.053822), Acc: 62.50% (31.85%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 5/20] [Batch 31/48] [Loss: 2.346630 (2.062972), Acc: 37.50% (32.03%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 32/48] [Loss: 0.843790 (2.026027), Acc: 62.50% (32.95%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 33/48] [Loss: 2.331318 (2.035006), Acc: 25.00% (32.72%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 34/48] [Loss: 1.471467 (2.018905), Acc: 50.00% (33.21%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 5/20] [Batch 35/48] [Loss: 1.154701 (1.994899), Acc: 50.00% (33.68%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 5/20] [Batch 36/48] [Loss: 0.958282 (1.966883), Acc: 62.50% (34.46%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 37/48] [Loss: 2.197910 (1.972962), Acc: 37.50% (34.54%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 38/48] [Loss: 2.622433 (1.989615), Acc: 12.50% (33.97%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 39/48] [Loss: 3.685968 (2.032024), Acc: 0.00% (33.12%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 40/48] [Loss: 2.298779 (2.038530), Acc: 50.00% (33.54%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 41/48] [Loss: 1.022011 (2.014327), Acc: 62.50% (34.23%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 42/48] [Loss: 1.465931 (2.001574), Acc: 50.00% (34.59%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 43/48] [Loss: 0.858383 (1.975592), Acc: 75.00% (35.51%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 5/20] [Batch 44/48] [Loss: 4.997837 (2.042753), Acc: 12.50% (35.00%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 5/20] [Batch 45/48] [Loss: 3.268854 (2.069408), Acc: 25.00% (34.78%)]Min label: 0\n",
      "Max label: 7\n",
      "\\r[Epoch 5/20] [Batch 46/48] [Loss: 4.049780 (2.111543), Acc: 25.00% (34.57%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 5/20] [Batch 47/48] [Loss: 0.665464 (2.081417), Acc: 50.00% (34.90%)]\n",
      "train , acc: 34.895833333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:44<00:00, 104.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 0/48] [Loss: 1.258768 (1.258768), Acc: 50.00% (50.00%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 1/48] [Loss: 2.030224 (1.644496), Acc: 37.50% (43.75%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 2/48] [Loss: 0.966951 (1.418648), Acc: 62.50% (50.00%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 3/48] [Loss: 3.268656 (1.881150), Acc: 25.00% (43.75%)]Min label: 0\n",
      "Max label: 8\n",
      "\\r[Epoch 6/20] [Batch 4/48] [Loss: 3.696815 (2.244283), Acc: 25.00% (40.00%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 6/20] [Batch 5/48] [Loss: 2.234510 (2.242654), Acc: 25.00% (37.50%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 6/48] [Loss: 3.022871 (2.354114), Acc: 25.00% (35.71%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 6/20] [Batch 7/48] [Loss: 2.159617 (2.329802), Acc: 50.00% (37.50%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 6/20] [Batch 8/48] [Loss: 2.232418 (2.318981), Acc: 25.00% (36.11%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 9/48] [Loss: 1.409199 (2.228003), Acc: 37.50% (36.25%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 10/48] [Loss: 3.420586 (2.336420), Acc: 25.00% (35.23%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 11/48] [Loss: 1.594785 (2.274617), Acc: 50.00% (36.46%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 6/20] [Batch 12/48] [Loss: 2.405428 (2.284679), Acc: 25.00% (35.58%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 13/48] [Loss: 2.094582 (2.271101), Acc: 50.00% (36.61%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 6/20] [Batch 14/48] [Loss: 1.982977 (2.251893), Acc: 25.00% (35.83%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 15/48] [Loss: 1.596645 (2.210940), Acc: 25.00% (35.16%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 6/20] [Batch 16/48] [Loss: 2.080066 (2.203241), Acc: 37.50% (35.29%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 17/48] [Loss: 1.688886 (2.174666), Acc: 37.50% (35.42%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 18/48] [Loss: 2.151866 (2.173466), Acc: 12.50% (34.21%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 19/48] [Loss: 2.085600 (2.169073), Acc: 37.50% (34.38%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 6/20] [Batch 20/48] [Loss: 2.542114 (2.186836), Acc: 25.00% (33.93%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 6/20] [Batch 21/48] [Loss: 2.641716 (2.207513), Acc: 25.00% (33.52%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 22/48] [Loss: 2.076006 (2.201795), Acc: 12.50% (32.61%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 6/20] [Batch 23/48] [Loss: 2.416989 (2.210762), Acc: 37.50% (32.81%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 24/48] [Loss: 2.588734 (2.225880), Acc: 0.00% (31.50%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 25/48] [Loss: 1.495431 (2.197786), Acc: 37.50% (31.73%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 26/48] [Loss: 2.088237 (2.193729), Acc: 25.00% (31.48%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 27/48] [Loss: 4.133677 (2.263013), Acc: 0.00% (30.36%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 28/48] [Loss: 2.245232 (2.262400), Acc: 12.50% (29.74%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 29/48] [Loss: 4.049460 (2.321968), Acc: 12.50% (29.17%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 6/20] [Batch 30/48] [Loss: 1.593287 (2.298462), Acc: 50.00% (29.84%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 6/20] [Batch 31/48] [Loss: 2.855627 (2.315874), Acc: 0.00% (28.91%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 6/20] [Batch 32/48] [Loss: 1.933183 (2.304277), Acc: 37.50% (29.17%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 6/20] [Batch 33/48] [Loss: 1.595761 (2.283438), Acc: 37.50% (29.41%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 34/48] [Loss: 3.770376 (2.325922), Acc: 25.00% (29.29%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 35/48] [Loss: 1.539120 (2.304067), Acc: 62.50% (30.21%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 36/48] [Loss: 2.511218 (2.309665), Acc: 12.50% (29.73%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 6/20] [Batch 37/48] [Loss: 0.768346 (2.269104), Acc: 75.00% (30.92%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 6/20] [Batch 38/48] [Loss: 2.056121 (2.263643), Acc: 25.00% (30.77%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 6/20] [Batch 39/48] [Loss: 2.228511 (2.262765), Acc: 50.00% (31.25%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 40/48] [Loss: 1.240131 (2.237823), Acc: 50.00% (31.71%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 6/20] [Batch 41/48] [Loss: 1.577763 (2.222107), Acc: 37.50% (31.85%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 6/20] [Batch 42/48] [Loss: 0.827354 (2.189671), Acc: 62.50% (32.56%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 6/20] [Batch 43/48] [Loss: 1.206355 (2.167323), Acc: 50.00% (32.95%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 6/20] [Batch 44/48] [Loss: 1.830265 (2.159833), Acc: 37.50% (33.06%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 6/20] [Batch 45/48] [Loss: 2.774816 (2.173202), Acc: 25.00% (32.88%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 6/20] [Batch 46/48] [Loss: 1.629737 (2.161639), Acc: 50.00% (33.24%)]Min label: 2\n",
      "Max label: 4\n",
      "\\r[Epoch 6/20] [Batch 47/48] [Loss: 3.739704 (2.194515), Acc: 0.00% (32.55%)]\n",
      "train , acc: 32.552083333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:47<00:00, 107.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 7/20] [Batch 0/48] [Loss: 1.403922 (1.403922), Acc: 37.50% (37.50%)]Min label: 0\n",
      "Max label: 6\n",
      "\\r[Epoch 7/20] [Batch 1/48] [Loss: 2.506375 (1.955148), Acc: 25.00% (31.25%)]Min label: 3\n",
      "Max label: 13\n",
      "\\r[Epoch 7/20] [Batch 2/48] [Loss: 3.400728 (2.437008), Acc: 12.50% (25.00%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 3/48] [Loss: 1.654185 (2.241302), Acc: 25.00% (25.00%)]Min label: 0\n",
      "Max label: 13\n",
      "\\r[Epoch 7/20] [Batch 4/48] [Loss: 3.624128 (2.517867), Acc: 0.00% (20.00%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 7/20] [Batch 5/48] [Loss: 2.238045 (2.471230), Acc: 37.50% (22.92%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 6/48] [Loss: 0.798436 (2.232260), Acc: 75.00% (30.36%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 7/20] [Batch 7/48] [Loss: 2.274561 (2.237547), Acc: 37.50% (31.25%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 7/20] [Batch 8/48] [Loss: 0.615389 (2.057308), Acc: 87.50% (37.50%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 9/48] [Loss: 0.961253 (1.947702), Acc: 75.00% (41.25%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 7/20] [Batch 10/48] [Loss: 3.291870 (2.069899), Acc: 37.50% (40.91%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 11/48] [Loss: 2.330251 (2.091595), Acc: 37.50% (40.62%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 12/48] [Loss: 2.371889 (2.113156), Acc: 37.50% (40.38%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 13/48] [Loss: 1.707584 (2.084187), Acc: 37.50% (40.18%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 14/48] [Loss: 2.980405 (2.143935), Acc: 25.00% (39.17%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 7/20] [Batch 15/48] [Loss: 2.671964 (2.176936), Acc: 25.00% (38.28%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 7/20] [Batch 16/48] [Loss: 2.122358 (2.173726), Acc: 25.00% (37.50%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 17/48] [Loss: 3.007037 (2.220021), Acc: 25.00% (36.81%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 7/20] [Batch 18/48] [Loss: 1.786665 (2.197213), Acc: 25.00% (36.18%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 19/48] [Loss: 2.790434 (2.226874), Acc: 12.50% (35.00%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 7/20] [Batch 20/48] [Loss: 0.675957 (2.153021), Acc: 62.50% (36.31%)]Min label: 1\n",
      "Max label: 9\n",
      "\\r[Epoch 7/20] [Batch 21/48] [Loss: 0.978580 (2.099637), Acc: 62.50% (37.50%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 7/20] [Batch 22/48] [Loss: 1.176005 (2.059479), Acc: 50.00% (38.04%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 7/20] [Batch 23/48] [Loss: 3.134913 (2.104289), Acc: 12.50% (36.98%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 7/20] [Batch 24/48] [Loss: 2.851521 (2.134178), Acc: 37.50% (37.00%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 7/20] [Batch 25/48] [Loss: 1.836440 (2.122727), Acc: 37.50% (37.02%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 7/20] [Batch 26/48] [Loss: 2.028601 (2.119241), Acc: 50.00% (37.50%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 7/20] [Batch 27/48] [Loss: 1.367078 (2.092378), Acc: 62.50% (38.39%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 7/20] [Batch 28/48] [Loss: 1.596444 (2.075276), Acc: 50.00% (38.79%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 29/48] [Loss: 3.481661 (2.122156), Acc: 12.50% (37.92%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 7/20] [Batch 30/48] [Loss: 2.853429 (2.145745), Acc: 12.50% (37.10%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 7/20] [Batch 31/48] [Loss: 1.478339 (2.124889), Acc: 50.00% (37.50%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 32/48] [Loss: 2.150028 (2.125651), Acc: 37.50% (37.50%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 33/48] [Loss: 2.113444 (2.125292), Acc: 12.50% (36.76%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 7/20] [Batch 34/48] [Loss: 1.561557 (2.109185), Acc: 50.00% (37.14%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 7/20] [Batch 35/48] [Loss: 1.658239 (2.096659), Acc: 37.50% (37.15%)]Min label: 3\n",
      "Max label: 6\n",
      "\\r[Epoch 7/20] [Batch 36/48] [Loss: 2.697384 (2.112894), Acc: 62.50% (37.84%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 37/48] [Loss: 2.191943 (2.114975), Acc: 25.00% (37.50%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 7/20] [Batch 38/48] [Loss: 2.497754 (2.124790), Acc: 37.50% (37.50%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 39/48] [Loss: 1.482832 (2.108741), Acc: 50.00% (37.81%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 40/48] [Loss: 1.948664 (2.104836), Acc: 37.50% (37.80%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 41/48] [Loss: 1.506490 (2.090590), Acc: 37.50% (37.80%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 7/20] [Batch 42/48] [Loss: 2.165479 (2.092332), Acc: 25.00% (37.50%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 43/48] [Loss: 1.902478 (2.088017), Acc: 37.50% (37.50%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 7/20] [Batch 44/48] [Loss: 2.833545 (2.104584), Acc: 37.50% (37.50%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 7/20] [Batch 45/48] [Loss: 1.808937 (2.098157), Acc: 50.00% (37.77%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 7/20] [Batch 46/48] [Loss: 0.705572 (2.068527), Acc: 75.00% (38.56%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 7/20] [Batch 47/48] [Loss: 1.763512 (2.062173), Acc: 0.00% (37.76%)]\n",
      "train , acc: 37.760416666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:40<00:00, 100.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 8/20] [Batch 0/48] [Loss: 1.634223 (1.634223), Acc: 62.50% (62.50%)]Min label: 1\n",
      "Max label: 10\n",
      "\\r[Epoch 8/20] [Batch 1/48] [Loss: 2.329971 (1.982097), Acc: 37.50% (50.00%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 8/20] [Batch 2/48] [Loss: 1.280824 (1.748339), Acc: 62.50% (54.17%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 3/48] [Loss: 1.197792 (1.610702), Acc: 62.50% (56.25%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 4/48] [Loss: 2.010007 (1.690563), Acc: 50.00% (55.00%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 5/48] [Loss: 1.946084 (1.733150), Acc: 50.00% (54.17%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 8/20] [Batch 6/48] [Loss: 1.754514 (1.736202), Acc: 62.50% (55.36%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 7/48] [Loss: 1.625927 (1.722418), Acc: 50.00% (54.69%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 8/20] [Batch 8/48] [Loss: 2.440009 (1.802150), Acc: 37.50% (52.78%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 8/20] [Batch 9/48] [Loss: 1.115970 (1.733532), Acc: 75.00% (55.00%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 8/20] [Batch 10/48] [Loss: 1.781986 (1.737937), Acc: 25.00% (52.27%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 11/48] [Loss: 1.730893 (1.737350), Acc: 37.50% (51.04%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 8/20] [Batch 12/48] [Loss: 2.194656 (1.772527), Acc: 37.50% (50.00%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 13/48] [Loss: 2.262625 (1.807534), Acc: 25.00% (48.21%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 8/20] [Batch 14/48] [Loss: 1.740164 (1.803043), Acc: 50.00% (48.33%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 15/48] [Loss: 1.578934 (1.789036), Acc: 50.00% (48.44%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 16/48] [Loss: 1.688281 (1.783110), Acc: 25.00% (47.06%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 8/20] [Batch 17/48] [Loss: 2.493016 (1.822549), Acc: 12.50% (45.14%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 18/48] [Loss: 1.259405 (1.792910), Acc: 37.50% (44.74%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 19/48] [Loss: 3.142690 (1.860399), Acc: 37.50% (44.38%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 20/48] [Loss: 1.659972 (1.850855), Acc: 50.00% (44.64%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 8/20] [Batch 21/48] [Loss: 2.053483 (1.860065), Acc: 50.00% (44.89%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 8/20] [Batch 22/48] [Loss: 1.077449 (1.826038), Acc: 37.50% (44.57%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 23/48] [Loss: 2.564711 (1.856816), Acc: 37.50% (44.27%)]Min label: 1\n",
      "Max label: 8\n",
      "\\r[Epoch 8/20] [Batch 24/48] [Loss: 1.158661 (1.828890), Acc: 75.00% (45.50%)]Min label: 2\n",
      "Max label: 6\n",
      "\\r[Epoch 8/20] [Batch 25/48] [Loss: 2.455542 (1.852992), Acc: 62.50% (46.15%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 26/48] [Loss: 2.514699 (1.877500), Acc: 37.50% (45.83%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 8/20] [Batch 27/48] [Loss: 2.491614 (1.899432), Acc: 50.00% (45.98%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 28/48] [Loss: 1.217727 (1.875925), Acc: 75.00% (46.98%)]Min label: 0\n",
      "Max label: 13\n",
      "\\r[Epoch 8/20] [Batch 29/48] [Loss: 2.002467 (1.880143), Acc: 50.00% (47.08%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 8/20] [Batch 30/48] [Loss: 3.986767 (1.948099), Acc: 25.00% (46.37%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 31/48] [Loss: 2.281885 (1.958530), Acc: 12.50% (45.31%)]Min label: 4\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 32/48] [Loss: 2.162944 (1.964724), Acc: 37.50% (45.08%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 33/48] [Loss: 1.517588 (1.951573), Acc: 37.50% (44.85%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 8/20] [Batch 34/48] [Loss: 0.967115 (1.923446), Acc: 75.00% (45.71%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 8/20] [Batch 35/48] [Loss: 2.782974 (1.947321), Acc: 0.00% (44.44%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 8/20] [Batch 36/48] [Loss: 4.475450 (2.015649), Acc: 12.50% (43.58%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 8/20] [Batch 37/48] [Loss: 3.027864 (2.042286), Acc: 0.00% (42.43%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 8/20] [Batch 38/48] [Loss: 3.103203 (2.069489), Acc: 12.50% (41.67%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 8/20] [Batch 39/48] [Loss: 1.980785 (2.067272), Acc: 37.50% (41.56%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 8/20] [Batch 40/48] [Loss: 1.096272 (2.043589), Acc: 62.50% (42.07%)]Min label: 0\n",
      "Max label: 17\n",
      "\\r[Epoch 8/20] [Batch 41/48] [Loss: 4.225255 (2.095533), Acc: 25.00% (41.67%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 42/48] [Loss: 2.784195 (2.111549), Acc: 37.50% (41.57%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 8/20] [Batch 43/48] [Loss: 2.473676 (2.119779), Acc: 25.00% (41.19%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 8/20] [Batch 44/48] [Loss: 1.618426 (2.108638), Acc: 37.50% (41.11%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 8/20] [Batch 45/48] [Loss: 3.076381 (2.129676), Acc: 12.50% (40.49%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 8/20] [Batch 46/48] [Loss: 1.347038 (2.113024), Acc: 62.50% (40.96%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 8/20] [Batch 47/48] [Loss: 1.180023 (2.093586), Acc: 50.00% (41.15%)]\n",
      "train , acc: 41.145833333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:38<00:00, 98.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 9/20] [Batch 0/48] [Loss: 1.628313 (1.628313), Acc: 25.00% (25.00%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 9/20] [Batch 1/48] [Loss: 2.519852 (2.074083), Acc: 25.00% (25.00%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 9/20] [Batch 2/48] [Loss: 2.595345 (2.247837), Acc: 12.50% (20.83%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 9/20] [Batch 3/48] [Loss: 1.739439 (2.120738), Acc: 37.50% (25.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 4/48] [Loss: 1.311188 (1.958828), Acc: 50.00% (30.00%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 9/20] [Batch 5/48] [Loss: 1.862291 (1.942738), Acc: 25.00% (29.17%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 9/20] [Batch 6/48] [Loss: 0.693951 (1.764340), Acc: 87.50% (37.50%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 9/20] [Batch 7/48] [Loss: 1.594914 (1.743162), Acc: 50.00% (39.06%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 8/48] [Loss: 2.683070 (1.847596), Acc: 12.50% (36.11%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 9/48] [Loss: 2.221156 (1.884952), Acc: 37.50% (36.25%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 9/20] [Batch 10/48] [Loss: 0.814681 (1.787655), Acc: 87.50% (40.91%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 9/20] [Batch 11/48] [Loss: 1.327216 (1.749285), Acc: 62.50% (42.71%)]Min label: 0\n",
      "Max label: 6\n",
      "\\r[Epoch 9/20] [Batch 12/48] [Loss: 0.703636 (1.668850), Acc: 87.50% (46.15%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 9/20] [Batch 13/48] [Loss: 2.084864 (1.698566), Acc: 25.00% (44.64%)]Min label: 2\n",
      "Max label: 6\n",
      "\\r[Epoch 9/20] [Batch 14/48] [Loss: 2.493640 (1.751571), Acc: 25.00% (43.33%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 15/48] [Loss: 2.860265 (1.820864), Acc: 37.50% (42.97%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 9/20] [Batch 16/48] [Loss: 1.254984 (1.787577), Acc: 75.00% (44.85%)]Min label: 0\n",
      "Max label: 7\n",
      "\\r[Epoch 9/20] [Batch 17/48] [Loss: 2.086920 (1.804207), Acc: 25.00% (43.75%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 18/48] [Loss: 1.787266 (1.803315), Acc: 12.50% (42.11%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 19/48] [Loss: 1.638116 (1.795055), Acc: 37.50% (41.88%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 9/20] [Batch 20/48] [Loss: 2.677146 (1.837060), Acc: 25.00% (41.07%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 9/20] [Batch 21/48] [Loss: 2.815509 (1.881535), Acc: 12.50% (39.77%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 9/20] [Batch 22/48] [Loss: 1.667543 (1.872231), Acc: 62.50% (40.76%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 9/20] [Batch 23/48] [Loss: 2.640051 (1.904223), Acc: 25.00% (40.10%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 24/48] [Loss: 2.464994 (1.926654), Acc: 37.50% (40.00%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 9/20] [Batch 25/48] [Loss: 2.574551 (1.951573), Acc: 25.00% (39.42%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 9/20] [Batch 26/48] [Loss: 3.101782 (1.994174), Acc: 25.00% (38.89%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 27/48] [Loss: 1.603907 (1.980235), Acc: 37.50% (38.84%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 9/20] [Batch 28/48] [Loss: 1.366383 (1.959068), Acc: 62.50% (39.66%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 29/48] [Loss: 1.131495 (1.931482), Acc: 50.00% (40.00%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 9/20] [Batch 30/48] [Loss: 2.455085 (1.948373), Acc: 37.50% (39.92%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 31/48] [Loss: 2.276085 (1.958614), Acc: 37.50% (39.84%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 9/20] [Batch 32/48] [Loss: 0.698087 (1.920416), Acc: 75.00% (40.91%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 9/20] [Batch 33/48] [Loss: 1.858500 (1.918595), Acc: 50.00% (41.18%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 34/48] [Loss: 1.776942 (1.914548), Acc: 25.00% (40.71%)]Min label: 2\n",
      "Max label: 10\n",
      "\\r[Epoch 9/20] [Batch 35/48] [Loss: 3.338208 (1.954094), Acc: 25.00% (40.28%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 9/20] [Batch 36/48] [Loss: 1.784479 (1.949510), Acc: 50.00% (40.54%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 9/20] [Batch 37/48] [Loss: 2.108417 (1.953691), Acc: 50.00% (40.79%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 9/20] [Batch 38/48] [Loss: 1.855422 (1.951172), Acc: 37.50% (40.71%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 9/20] [Batch 39/48] [Loss: 2.194847 (1.957264), Acc: 37.50% (40.62%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 9/20] [Batch 40/48] [Loss: 3.214975 (1.987939), Acc: 37.50% (40.55%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 9/20] [Batch 41/48] [Loss: 2.577496 (2.001977), Acc: 50.00% (40.77%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 9/20] [Batch 42/48] [Loss: 2.184219 (2.006215), Acc: 50.00% (40.99%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 9/20] [Batch 43/48] [Loss: 2.538107 (2.018303), Acc: 50.00% (41.19%)]Min label: 1\n",
      "Max label: 8\n",
      "\\r[Epoch 9/20] [Batch 44/48] [Loss: 2.290650 (2.024355), Acc: 12.50% (40.56%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 9/20] [Batch 45/48] [Loss: 2.647576 (2.037904), Acc: 25.00% (40.22%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 9/20] [Batch 46/48] [Loss: 0.873366 (2.013126), Acc: 62.50% (40.69%)]Min label: 1\n",
      "Max label: 1\n",
      "\\r[Epoch 9/20] [Batch 47/48] [Loss: 6.705228 (2.110878), Acc: 0.00% (39.84%)]\n",
      "train , acc: 39.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:37<00:00, 97.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 0/48] [Loss: 2.165782 (2.165782), Acc: 25.00% (25.00%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 10/20] [Batch 1/48] [Loss: 1.661118 (1.913450), Acc: 37.50% (31.25%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 10/20] [Batch 2/48] [Loss: 1.353642 (1.726847), Acc: 62.50% (41.67%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 10/20] [Batch 3/48] [Loss: 1.923532 (1.776018), Acc: 50.00% (43.75%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 10/20] [Batch 4/48] [Loss: 1.294778 (1.679770), Acc: 50.00% (45.00%)]Min label: 0\n",
      "Max label: 7\n",
      "\\r[Epoch 10/20] [Batch 5/48] [Loss: 1.736363 (1.689202), Acc: 37.50% (43.75%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 10/20] [Batch 6/48] [Loss: 2.289976 (1.775027), Acc: 37.50% (42.86%)]Min label: 4\n",
      "Max label: 12\n",
      "\\r[Epoch 10/20] [Batch 7/48] [Loss: 3.199398 (1.953073), Acc: 25.00% (40.62%)]Min label: 2\n",
      "Max label: 4\n",
      "\\r[Epoch 10/20] [Batch 8/48] [Loss: 3.299858 (2.102716), Acc: 12.50% (37.50%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 9/48] [Loss: 2.191476 (2.111592), Acc: 25.00% (36.25%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 10/20] [Batch 10/48] [Loss: 1.457773 (2.052154), Acc: 75.00% (39.77%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 11/48] [Loss: 1.114588 (1.974024), Acc: 50.00% (40.62%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 10/20] [Batch 12/48] [Loss: 2.293840 (1.998625), Acc: 25.00% (39.42%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 13/48] [Loss: 1.710932 (1.978075), Acc: 37.50% (39.29%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 10/20] [Batch 14/48] [Loss: 2.140084 (1.988876), Acc: 37.50% (39.17%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 15/48] [Loss: 2.339463 (2.010788), Acc: 25.00% (38.28%)]Min label: 0\n",
      "Max label: 9\n",
      "\\r[Epoch 10/20] [Batch 16/48] [Loss: 1.122547 (1.958538), Acc: 50.00% (38.97%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 17/48] [Loss: 2.510859 (1.989223), Acc: 37.50% (38.89%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 10/20] [Batch 18/48] [Loss: 1.163463 (1.945762), Acc: 37.50% (38.82%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 10/20] [Batch 19/48] [Loss: 1.708415 (1.933894), Acc: 37.50% (38.75%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 10/20] [Batch 20/48] [Loss: 1.669481 (1.921303), Acc: 50.00% (39.29%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 10/20] [Batch 21/48] [Loss: 2.618778 (1.953006), Acc: 12.50% (38.07%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 22/48] [Loss: 1.475236 (1.932234), Acc: 37.50% (38.04%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 23/48] [Loss: 1.609832 (1.918800), Acc: 50.00% (38.54%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 10/20] [Batch 24/48] [Loss: 1.349439 (1.896026), Acc: 62.50% (39.50%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 10/20] [Batch 25/48] [Loss: 2.133417 (1.905156), Acc: 25.00% (38.94%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 10/20] [Batch 26/48] [Loss: 1.874961 (1.904038), Acc: 62.50% (39.81%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 10/20] [Batch 27/48] [Loss: 2.486663 (1.924846), Acc: 12.50% (38.84%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 28/48] [Loss: 1.544479 (1.911730), Acc: 50.00% (39.22%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 10/20] [Batch 29/48] [Loss: 1.618156 (1.901944), Acc: 62.50% (40.00%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 10/20] [Batch 30/48] [Loss: 1.029653 (1.873806), Acc: 62.50% (40.73%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 31/48] [Loss: 1.006033 (1.846688), Acc: 62.50% (41.41%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 10/20] [Batch 32/48] [Loss: 1.480343 (1.835586), Acc: 25.00% (40.91%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 33/48] [Loss: 2.151979 (1.844892), Acc: 37.50% (40.81%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 10/20] [Batch 34/48] [Loss: 2.152777 (1.853689), Acc: 25.00% (40.36%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 35/48] [Loss: 1.717668 (1.849911), Acc: 37.50% (40.28%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 36/48] [Loss: 0.995747 (1.826825), Acc: 75.00% (41.22%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 10/20] [Batch 37/48] [Loss: 0.248490 (1.785290), Acc: 87.50% (42.43%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 38/48] [Loss: 1.495685 (1.777864), Acc: 37.50% (42.31%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 39/48] [Loss: 1.727413 (1.776603), Acc: 50.00% (42.50%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 10/20] [Batch 40/48] [Loss: 1.975260 (1.781448), Acc: 37.50% (42.38%)]Min label: 2\n",
      "Max label: 7\n",
      "\\r[Epoch 10/20] [Batch 41/48] [Loss: 2.162702 (1.790526), Acc: 37.50% (42.26%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 10/20] [Batch 42/48] [Loss: 0.804407 (1.767593), Acc: 62.50% (42.73%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 10/20] [Batch 43/48] [Loss: 1.828744 (1.768982), Acc: 50.00% (42.90%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 10/20] [Batch 44/48] [Loss: 2.153209 (1.777521), Acc: 25.00% (42.50%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 10/20] [Batch 45/48] [Loss: 3.416784 (1.813157), Acc: 12.50% (41.85%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 10/20] [Batch 46/48] [Loss: 1.592698 (1.808466), Acc: 50.00% (42.02%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 10/20] [Batch 47/48] [Loss: 0.892778 (1.789389), Acc: 50.00% (42.19%)]\n",
      "train , acc: 42.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:49<00:00, 109.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 11 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 11/20] [Batch 0/48] [Loss: 1.600030 (1.600030), Acc: 37.50% (37.50%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 1/48] [Loss: 0.956315 (1.278173), Acc: 62.50% (50.00%)]Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 11/20] [Batch 2/48] [Loss: 0.254546 (0.936964), Acc: 100.00% (66.67%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 3/48] [Loss: 0.409368 (0.805065), Acc: 87.50% (71.88%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 4/48] [Loss: 1.034323 (0.850917), Acc: 62.50% (70.00%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 5/48] [Loss: 1.833696 (1.014713), Acc: 62.50% (68.75%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 11/20] [Batch 6/48] [Loss: 1.214273 (1.043222), Acc: 75.00% (69.64%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 7/48] [Loss: 2.676020 (1.247321), Acc: 37.50% (65.62%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 8/48] [Loss: 2.109903 (1.343164), Acc: 75.00% (66.67%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 9/48] [Loss: 1.564115 (1.365259), Acc: 62.50% (66.25%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 11/20] [Batch 10/48] [Loss: 2.457440 (1.464548), Acc: 50.00% (64.77%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 11/20] [Batch 11/48] [Loss: 2.099975 (1.517500), Acc: 50.00% (63.54%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 11/20] [Batch 12/48] [Loss: 1.545833 (1.519680), Acc: 75.00% (64.42%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 13/48] [Loss: 0.541650 (1.449820), Acc: 75.00% (65.18%)]Min label: 4\n",
      "Max label: 15\n",
      "\\r[Epoch 11/20] [Batch 14/48] [Loss: 2.817575 (1.541004), Acc: 25.00% (62.50%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 15/48] [Loss: 2.072685 (1.574234), Acc: 62.50% (62.50%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 11/20] [Batch 16/48] [Loss: 1.329719 (1.559851), Acc: 62.50% (62.50%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 11/20] [Batch 17/48] [Loss: 1.653333 (1.565044), Acc: 37.50% (61.11%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 18/48] [Loss: 1.102302 (1.540690), Acc: 50.00% (60.53%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 11/20] [Batch 19/48] [Loss: 1.848218 (1.556066), Acc: 37.50% (59.38%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 20/48] [Loss: 1.744362 (1.565032), Acc: 37.50% (58.33%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 11/20] [Batch 21/48] [Loss: 1.430018 (1.558895), Acc: 50.00% (57.95%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 22/48] [Loss: 2.117596 (1.583187), Acc: 62.50% (58.15%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 11/20] [Batch 23/48] [Loss: 2.211887 (1.609383), Acc: 12.50% (56.25%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 11/20] [Batch 24/48] [Loss: 0.373497 (1.559947), Acc: 87.50% (57.50%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 25/48] [Loss: 1.240531 (1.547662), Acc: 62.50% (57.69%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 26/48] [Loss: 3.875074 (1.633862), Acc: 0.00% (55.56%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 27/48] [Loss: 1.284546 (1.621387), Acc: 75.00% (56.25%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 28/48] [Loss: 1.208414 (1.607146), Acc: 62.50% (56.47%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 11/20] [Batch 29/48] [Loss: 2.179259 (1.626217), Acc: 25.00% (55.42%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 30/48] [Loss: 1.189171 (1.612119), Acc: 50.00% (55.24%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 11/20] [Batch 31/48] [Loss: 3.291636 (1.664603), Acc: 12.50% (53.91%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 11/20] [Batch 32/48] [Loss: 1.589510 (1.662328), Acc: 62.50% (54.17%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 33/48] [Loss: 2.837670 (1.696897), Acc: 37.50% (53.68%)]Min label: 2\n",
      "Max label: 6\n",
      "\\r[Epoch 11/20] [Batch 34/48] [Loss: 2.015230 (1.705992), Acc: 37.50% (53.21%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 11/20] [Batch 35/48] [Loss: 0.740328 (1.679168), Acc: 62.50% (53.47%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 36/48] [Loss: 0.757546 (1.654259), Acc: 75.00% (54.05%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 37/48] [Loss: 0.860464 (1.633370), Acc: 62.50% (54.28%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 38/48] [Loss: 2.437676 (1.653993), Acc: 50.00% (54.17%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 11/20] [Batch 39/48] [Loss: 2.744110 (1.681246), Acc: 37.50% (53.75%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 40/48] [Loss: 2.535887 (1.702091), Acc: 50.00% (53.66%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 11/20] [Batch 41/48] [Loss: 1.589325 (1.699406), Acc: 75.00% (54.17%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 11/20] [Batch 42/48] [Loss: 1.916996 (1.704466), Acc: 62.50% (54.36%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 11/20] [Batch 43/48] [Loss: 1.146682 (1.691789), Acc: 62.50% (54.55%)]Min label: 3\n",
      "Max label: 13\n",
      "\\r[Epoch 11/20] [Batch 44/48] [Loss: 1.268508 (1.682383), Acc: 62.50% (54.72%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 11/20] [Batch 45/48] [Loss: 3.063234 (1.712402), Acc: 0.00% (53.53%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 46/48] [Loss: 1.150365 (1.700443), Acc: 62.50% (53.72%)]Min label: 7\n",
      "Max label: 12\n",
      "\\r[Epoch 11/20] [Batch 47/48] [Loss: 4.112291 (1.750690), Acc: 0.00% (52.60%)]\n",
      "train , acc: 52.604166666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:34<00:00, 94.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 12 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 12/20] [Batch 0/48] [Loss: 1.601955 (1.601955), Acc: 50.00% (50.00%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 12/20] [Batch 1/48] [Loss: 2.401782 (2.001868), Acc: 37.50% (43.75%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 2/48] [Loss: 1.647304 (1.883680), Acc: 25.00% (37.50%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 12/20] [Batch 3/48] [Loss: 1.304092 (1.738783), Acc: 75.00% (46.88%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 4/48] [Loss: 1.186968 (1.628420), Acc: 62.50% (50.00%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 12/20] [Batch 5/48] [Loss: 0.861087 (1.500531), Acc: 75.00% (54.17%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 6/48] [Loss: 1.519900 (1.503298), Acc: 37.50% (51.79%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 7/48] [Loss: 0.582354 (1.388180), Acc: 62.50% (53.12%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 8/48] [Loss: 0.871362 (1.330756), Acc: 75.00% (55.56%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 12/20] [Batch 9/48] [Loss: 2.023386 (1.400019), Acc: 37.50% (53.75%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 10/48] [Loss: 0.526638 (1.320621), Acc: 75.00% (55.68%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 11/48] [Loss: 1.818143 (1.362081), Acc: 37.50% (54.17%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 12/20] [Batch 12/48] [Loss: 1.477575 (1.370965), Acc: 75.00% (55.77%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 12/20] [Batch 13/48] [Loss: 1.240184 (1.361624), Acc: 75.00% (57.14%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 14/48] [Loss: 2.660295 (1.448202), Acc: 37.50% (55.83%)]Min label: 1\n",
      "Max label: 9\n",
      "\\r[Epoch 12/20] [Batch 15/48] [Loss: 0.904873 (1.414244), Acc: 62.50% (56.25%)]Min label: 3\n",
      "Max label: 17\n",
      "\\r[Epoch 12/20] [Batch 16/48] [Loss: 0.627241 (1.367949), Acc: 75.00% (57.35%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 17/48] [Loss: 0.601274 (1.325356), Acc: 87.50% (59.03%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 18/48] [Loss: 1.589444 (1.339256), Acc: 37.50% (57.89%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 19/48] [Loss: 1.104359 (1.327511), Acc: 62.50% (58.12%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 12/20] [Batch 20/48] [Loss: 1.668749 (1.343760), Acc: 37.50% (57.14%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 12/20] [Batch 21/48] [Loss: 2.639822 (1.402672), Acc: 25.00% (55.68%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 12/20] [Batch 22/48] [Loss: 1.656204 (1.413695), Acc: 75.00% (56.52%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 23/48] [Loss: 0.954509 (1.394563), Acc: 62.50% (56.77%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 12/20] [Batch 24/48] [Loss: 1.923681 (1.415727), Acc: 50.00% (56.50%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 25/48] [Loss: 1.350083 (1.413202), Acc: 37.50% (55.77%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 12/20] [Batch 26/48] [Loss: 2.453818 (1.451744), Acc: 37.50% (55.09%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 12/20] [Batch 27/48] [Loss: 1.192774 (1.442495), Acc: 62.50% (55.36%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 12/20] [Batch 28/48] [Loss: 1.822180 (1.455587), Acc: 25.00% (54.31%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 29/48] [Loss: 1.859798 (1.469061), Acc: 37.50% (53.75%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 30/48] [Loss: 0.337545 (1.432561), Acc: 100.00% (55.24%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 31/48] [Loss: 2.219963 (1.457167), Acc: 12.50% (53.91%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 12/20] [Batch 32/48] [Loss: 0.567767 (1.430215), Acc: 75.00% (54.55%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 33/48] [Loss: 2.000478 (1.446988), Acc: 50.00% (54.41%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 34/48] [Loss: 1.682460 (1.453716), Acc: 62.50% (54.64%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 35/48] [Loss: 1.417873 (1.452720), Acc: 50.00% (54.51%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 12/20] [Batch 36/48] [Loss: 3.205478 (1.500092), Acc: 12.50% (53.38%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 37/48] [Loss: 2.861758 (1.535925), Acc: 25.00% (52.63%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 38/48] [Loss: 3.129469 (1.576785), Acc: 37.50% (52.24%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 12/20] [Batch 39/48] [Loss: 1.591315 (1.577148), Acc: 50.00% (52.19%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 12/20] [Batch 40/48] [Loss: 1.785831 (1.582238), Acc: 50.00% (52.13%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 12/20] [Batch 41/48] [Loss: 0.910775 (1.566251), Acc: 75.00% (52.68%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 42/48] [Loss: 1.273060 (1.559433), Acc: 62.50% (52.91%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 12/20] [Batch 43/48] [Loss: 0.854003 (1.543400), Acc: 62.50% (53.12%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 12/20] [Batch 44/48] [Loss: 1.992406 (1.553378), Acc: 25.00% (52.50%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 12/20] [Batch 45/48] [Loss: 1.172892 (1.545107), Acc: 50.00% (52.45%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 12/20] [Batch 46/48] [Loss: 1.121496 (1.536094), Acc: 62.50% (52.66%)]Min label: 5\n",
      "Max label: 5\n",
      "\\r[Epoch 12/20] [Batch 47/48] [Loss: 2.257080 (1.551114), Acc: 50.00% (52.60%)]\n",
      "train , acc: 52.604166666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:41<00:00, 101.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 13 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 0/48] [Loss: 2.435503 (2.435503), Acc: 25.00% (25.00%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 1/48] [Loss: 1.732130 (2.083817), Acc: 25.00% (25.00%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 13/20] [Batch 2/48] [Loss: 1.681514 (1.949716), Acc: 50.00% (33.33%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 13/20] [Batch 3/48] [Loss: 1.407465 (1.814153), Acc: 50.00% (37.50%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 13/20] [Batch 4/48] [Loss: 1.073760 (1.666074), Acc: 62.50% (42.50%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 5/48] [Loss: 1.104483 (1.572476), Acc: 62.50% (45.83%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 13/20] [Batch 6/48] [Loss: 2.000367 (1.633603), Acc: 62.50% (48.21%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 7/48] [Loss: 1.864771 (1.662499), Acc: 37.50% (46.88%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 8/48] [Loss: 1.935858 (1.692872), Acc: 37.50% (45.83%)]Min label: 4\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 9/48] [Loss: 2.006367 (1.724222), Acc: 37.50% (45.00%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 10/48] [Loss: 2.143846 (1.762369), Acc: 25.00% (43.18%)]Min label: 3\n",
      "Max label: 17\n",
      "\\r[Epoch 13/20] [Batch 11/48] [Loss: 2.272887 (1.804913), Acc: 37.50% (42.71%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 13/20] [Batch 12/48] [Loss: 1.737523 (1.799729), Acc: 50.00% (43.27%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 13/48] [Loss: 1.401632 (1.771293), Acc: 50.00% (43.75%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 13/20] [Batch 14/48] [Loss: 1.225155 (1.734884), Acc: 50.00% (44.17%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 13/20] [Batch 15/48] [Loss: 1.765759 (1.736814), Acc: 37.50% (43.75%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 13/20] [Batch 16/48] [Loss: 2.489234 (1.781074), Acc: 37.50% (43.38%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 13/20] [Batch 17/48] [Loss: 1.457708 (1.763109), Acc: 50.00% (43.75%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 18/48] [Loss: 0.907512 (1.718078), Acc: 62.50% (44.74%)]Min label: 1\n",
      "Max label: 10\n",
      "\\r[Epoch 13/20] [Batch 19/48] [Loss: 1.019577 (1.683153), Acc: 75.00% (46.25%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 20/48] [Loss: 1.303324 (1.665065), Acc: 50.00% (46.43%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 13/20] [Batch 21/48] [Loss: 1.578591 (1.661135), Acc: 62.50% (47.16%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 13/20] [Batch 22/48] [Loss: 1.479728 (1.653248), Acc: 25.00% (46.20%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 13/20] [Batch 23/48] [Loss: 1.138121 (1.631784), Acc: 62.50% (46.88%)]Min label: 1\n",
      "Max label: 10\n",
      "\\r[Epoch 13/20] [Batch 24/48] [Loss: 1.073673 (1.609460), Acc: 50.00% (47.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 25/48] [Loss: 1.722858 (1.613821), Acc: 37.50% (46.63%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 26/48] [Loss: 0.938278 (1.588801), Acc: 75.00% (47.69%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 13/20] [Batch 27/48] [Loss: 0.700841 (1.557088), Acc: 75.00% (48.66%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 28/48] [Loss: 1.215892 (1.545323), Acc: 50.00% (48.71%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 13/20] [Batch 29/48] [Loss: 1.390621 (1.540166), Acc: 50.00% (48.75%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 13/20] [Batch 30/48] [Loss: 1.357741 (1.534281), Acc: 50.00% (48.79%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 31/48] [Loss: 1.466276 (1.532156), Acc: 50.00% (48.83%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 32/48] [Loss: 1.452996 (1.529757), Acc: 62.50% (49.24%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 33/48] [Loss: 2.545313 (1.559627), Acc: 37.50% (48.90%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 34/48] [Loss: 1.930992 (1.570237), Acc: 37.50% (48.57%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 13/20] [Batch 35/48] [Loss: 1.842002 (1.577786), Acc: 37.50% (48.26%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 13/20] [Batch 36/48] [Loss: 0.994348 (1.562017), Acc: 75.00% (48.99%)]Min label: 2\n",
      "Max label: 6\n",
      "\\r[Epoch 13/20] [Batch 37/48] [Loss: 0.727251 (1.540050), Acc: 62.50% (49.34%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 13/20] [Batch 38/48] [Loss: 2.561814 (1.566249), Acc: 25.00% (48.72%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 39/48] [Loss: 1.572718 (1.566411), Acc: 62.50% (49.06%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 13/20] [Batch 40/48] [Loss: 1.933449 (1.575363), Acc: 12.50% (48.17%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 41/48] [Loss: 1.916241 (1.583479), Acc: 75.00% (48.81%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 13/20] [Batch 42/48] [Loss: 1.698009 (1.586142), Acc: 50.00% (48.84%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 13/20] [Batch 43/48] [Loss: 1.498628 (1.584154), Acc: 37.50% (48.58%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 13/20] [Batch 44/48] [Loss: 1.528904 (1.582926), Acc: 50.00% (48.61%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 13/20] [Batch 45/48] [Loss: 1.363342 (1.578152), Acc: 62.50% (48.91%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 13/20] [Batch 46/48] [Loss: 1.406927 (1.574509), Acc: 50.00% (48.94%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 13/20] [Batch 47/48] [Loss: 2.116519 (1.585801), Acc: 50.00% (48.96%)]\n",
      "train , acc: 48.958333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:34<00:00, 94.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 14 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 0/48] [Loss: 0.347670 (0.347670), Acc: 100.00% (100.00%)]Min label: 0\n",
      "Max label: 13\n",
      "\\r[Epoch 14/20] [Batch 1/48] [Loss: 1.726286 (1.036978), Acc: 37.50% (68.75%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 14/20] [Batch 2/48] [Loss: 1.474231 (1.182729), Acc: 62.50% (66.67%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 14/20] [Batch 3/48] [Loss: 0.780582 (1.082192), Acc: 75.00% (68.75%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 4/48] [Loss: 0.705937 (1.006941), Acc: 62.50% (67.50%)]Min label: 0\n",
      "Max label: 17\n",
      "\\r[Epoch 14/20] [Batch 5/48] [Loss: 2.145843 (1.196758), Acc: 37.50% (62.50%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 14/20] [Batch 6/48] [Loss: 2.069176 (1.321389), Acc: 62.50% (62.50%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 7/48] [Loss: 0.546734 (1.224557), Acc: 62.50% (62.50%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 8/48] [Loss: 1.239726 (1.226243), Acc: 75.00% (63.89%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 9/48] [Loss: 1.093917 (1.213010), Acc: 62.50% (63.75%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 10/48] [Loss: 1.546415 (1.243320), Acc: 50.00% (62.50%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 14/20] [Batch 11/48] [Loss: 2.581963 (1.354873), Acc: 37.50% (60.42%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 12/48] [Loss: 1.718595 (1.382852), Acc: 25.00% (57.69%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 13/48] [Loss: 1.918964 (1.421146), Acc: 37.50% (56.25%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 14/20] [Batch 14/48] [Loss: 3.555814 (1.563457), Acc: 12.50% (53.33%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 15/48] [Loss: 1.566426 (1.563642), Acc: 50.00% (53.12%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 14/20] [Batch 16/48] [Loss: 3.300886 (1.665833), Acc: 50.00% (52.94%)]Min label: 0\n",
      "Max label: 13\n",
      "\\r[Epoch 14/20] [Batch 17/48] [Loss: 2.566381 (1.715864), Acc: 37.50% (52.08%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 18/48] [Loss: 2.924520 (1.779477), Acc: 37.50% (51.32%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 19/48] [Loss: 0.553143 (1.718160), Acc: 87.50% (53.12%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 20/48] [Loss: 1.713941 (1.717959), Acc: 62.50% (53.57%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 21/48] [Loss: 0.925804 (1.681952), Acc: 62.50% (53.98%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 14/20] [Batch 22/48] [Loss: 1.487091 (1.673480), Acc: 62.50% (54.35%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 14/20] [Batch 23/48] [Loss: 1.081350 (1.648808), Acc: 62.50% (54.69%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 24/48] [Loss: 1.234380 (1.632231), Acc: 62.50% (55.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 25/48] [Loss: 2.088677 (1.649787), Acc: 37.50% (54.33%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 26/48] [Loss: 1.389145 (1.640133), Acc: 50.00% (54.17%)]Min label: 4\n",
      "Max label: 10\n",
      "\\r[Epoch 14/20] [Batch 27/48] [Loss: 2.487717 (1.670404), Acc: 50.00% (54.02%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 28/48] [Loss: 0.460556 (1.628685), Acc: 75.00% (54.74%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 14/20] [Batch 29/48] [Loss: 1.885983 (1.637262), Acc: 50.00% (54.58%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 14/20] [Batch 30/48] [Loss: 2.287800 (1.658247), Acc: 37.50% (54.03%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 31/48] [Loss: 0.935698 (1.635667), Acc: 75.00% (54.69%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 32/48] [Loss: 1.308868 (1.625764), Acc: 62.50% (54.92%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 33/48] [Loss: 1.273097 (1.615392), Acc: 50.00% (54.78%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 14/20] [Batch 34/48] [Loss: 0.913989 (1.595352), Acc: 50.00% (54.64%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 35/48] [Loss: 2.573441 (1.622521), Acc: 25.00% (53.82%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 14/20] [Batch 36/48] [Loss: 1.858682 (1.628903), Acc: 50.00% (53.72%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 37/48] [Loss: 1.615106 (1.628540), Acc: 50.00% (53.62%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 14/20] [Batch 38/48] [Loss: 1.228411 (1.618281), Acc: 50.00% (53.53%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 39/48] [Loss: 0.788781 (1.597543), Acc: 62.50% (53.75%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 40/48] [Loss: 2.154810 (1.611135), Acc: 12.50% (52.74%)]Min label: 0\n",
      "Max label: 11\n",
      "\\r[Epoch 14/20] [Batch 41/48] [Loss: 1.754815 (1.614556), Acc: 50.00% (52.68%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 14/20] [Batch 42/48] [Loss: 1.625502 (1.614810), Acc: 37.50% (52.33%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 43/48] [Loss: 1.423889 (1.610471), Acc: 50.00% (52.27%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 14/20] [Batch 44/48] [Loss: 0.438575 (1.584429), Acc: 100.00% (53.33%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 14/20] [Batch 45/48] [Loss: 0.930801 (1.570220), Acc: 62.50% (53.53%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 14/20] [Batch 46/48] [Loss: 1.332910 (1.565171), Acc: 62.50% (53.72%)]Min label: 5\n",
      "Max label: 7\n",
      "\\r[Epoch 14/20] [Batch 47/48] [Loss: 3.110513 (1.597365), Acc: 0.00% (52.60%)]\n",
      "train , acc: 52.604166666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:37<00:00, 97.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 0/48] [Loss: 0.375288 (0.375288), Acc: 87.50% (87.50%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 1/48] [Loss: 1.260379 (0.817833), Acc: 75.00% (81.25%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 15/20] [Batch 2/48] [Loss: 0.588934 (0.741534), Acc: 62.50% (75.00%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 3/48] [Loss: 1.483199 (0.926950), Acc: 75.00% (75.00%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 15/20] [Batch 4/48] [Loss: 2.010948 (1.143750), Acc: 37.50% (67.50%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 15/20] [Batch 5/48] [Loss: 2.578280 (1.382838), Acc: 37.50% (62.50%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 6/48] [Loss: 2.819110 (1.588020), Acc: 50.00% (60.71%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 15/20] [Batch 7/48] [Loss: 1.930641 (1.630847), Acc: 50.00% (59.38%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 15/20] [Batch 8/48] [Loss: 1.568407 (1.623910), Acc: 37.50% (56.94%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 15/20] [Batch 9/48] [Loss: 0.492704 (1.510789), Acc: 100.00% (61.25%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 10/48] [Loss: 0.623313 (1.430109), Acc: 87.50% (63.64%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 11/48] [Loss: 0.941615 (1.389401), Acc: 50.00% (62.50%)]Min label: 2\n",
      "Max label: 10\n",
      "\\r[Epoch 15/20] [Batch 12/48] [Loss: 1.442203 (1.393463), Acc: 50.00% (61.54%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 15/20] [Batch 13/48] [Loss: 1.155481 (1.376464), Acc: 62.50% (61.61%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 14/48] [Loss: 2.498693 (1.451280), Acc: 25.00% (59.17%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 15/20] [Batch 15/48] [Loss: 2.535042 (1.519015), Acc: 25.00% (57.03%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 15/20] [Batch 16/48] [Loss: 0.474567 (1.457577), Acc: 87.50% (58.82%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 15/20] [Batch 17/48] [Loss: 1.007482 (1.432571), Acc: 50.00% (58.33%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 18/48] [Loss: 1.653633 (1.444206), Acc: 37.50% (57.24%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 15/20] [Batch 19/48] [Loss: 2.884934 (1.516243), Acc: 12.50% (55.00%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 20/48] [Loss: 1.097215 (1.496289), Acc: 75.00% (55.95%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 15/20] [Batch 21/48] [Loss: 1.817924 (1.510909), Acc: 50.00% (55.68%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 15/20] [Batch 22/48] [Loss: 2.580828 (1.557427), Acc: 25.00% (54.35%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 23/48] [Loss: 0.511413 (1.513843), Acc: 87.50% (55.73%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 24/48] [Loss: 2.057354 (1.535583), Acc: 50.00% (55.50%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 15/20] [Batch 25/48] [Loss: 2.404726 (1.569012), Acc: 50.00% (55.29%)]Min label: 1\n",
      "Max label: 10\n",
      "\\r[Epoch 15/20] [Batch 26/48] [Loss: 1.507851 (1.566747), Acc: 37.50% (54.63%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 27/48] [Loss: 1.609145 (1.568261), Acc: 62.50% (54.91%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 28/48] [Loss: 2.622818 (1.604625), Acc: 25.00% (53.88%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 29/48] [Loss: 0.755029 (1.576305), Acc: 87.50% (55.00%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 30/48] [Loss: 1.510749 (1.574190), Acc: 50.00% (54.84%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 15/20] [Batch 31/48] [Loss: 0.937040 (1.554280), Acc: 75.00% (55.47%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 32/48] [Loss: 0.428078 (1.520152), Acc: 87.50% (56.44%)]Min label: 1\n",
      "Max label: 7\n",
      "\\r[Epoch 15/20] [Batch 33/48] [Loss: 2.495961 (1.548852), Acc: 25.00% (55.51%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 15/20] [Batch 34/48] [Loss: 1.959440 (1.560584), Acc: 37.50% (55.00%)]Min label: 2\n",
      "Max label: 8\n",
      "\\r[Epoch 15/20] [Batch 35/48] [Loss: 2.005495 (1.572942), Acc: 50.00% (54.86%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 15/20] [Batch 36/48] [Loss: 0.731727 (1.550207), Acc: 87.50% (55.74%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 37/48] [Loss: 0.645660 (1.526403), Acc: 87.50% (56.58%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 15/20] [Batch 38/48] [Loss: 1.514603 (1.526100), Acc: 62.50% (56.73%)]Min label: 1\n",
      "Max label: 6\n",
      "\\r[Epoch 15/20] [Batch 39/48] [Loss: 1.424662 (1.523564), Acc: 50.00% (56.56%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 15/20] [Batch 40/48] [Loss: 2.195634 (1.539956), Acc: 50.00% (56.40%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 15/20] [Batch 41/48] [Loss: 1.100451 (1.529492), Acc: 62.50% (56.55%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 15/20] [Batch 42/48] [Loss: 0.673258 (1.509579), Acc: 87.50% (57.27%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 15/20] [Batch 43/48] [Loss: 2.575885 (1.533814), Acc: 50.00% (57.10%)]Min label: 1\n",
      "Max label: 9\n",
      "\\r[Epoch 15/20] [Batch 44/48] [Loss: 2.422990 (1.553573), Acc: 50.00% (56.94%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 15/20] [Batch 45/48] [Loss: 3.414538 (1.594029), Acc: 37.50% (56.52%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 15/20] [Batch 46/48] [Loss: 0.539965 (1.571602), Acc: 75.00% (56.91%)]Min label: 3\n",
      "Max label: 4\n",
      "\\r[Epoch 15/20] [Batch 47/48] [Loss: 3.756932 (1.617130), Acc: 0.00% (55.73%)]\n",
      "train , acc: 55.729166666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:35<00:00, 95.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 16 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 3\n",
      "Max label: 7\n",
      "\\r[Epoch 16/20] [Batch 0/48] [Loss: 1.882140 (1.882140), Acc: 25.00% (25.00%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 16/20] [Batch 1/48] [Loss: 1.381754 (1.631947), Acc: 37.50% (31.25%)]Min label: 0\n",
      "Max label: 6\n",
      "\\r[Epoch 16/20] [Batch 2/48] [Loss: 1.586708 (1.616867), Acc: 25.00% (29.17%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 3/48] [Loss: 2.010149 (1.715187), Acc: 25.00% (28.12%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 4/48] [Loss: 0.825937 (1.537337), Acc: 75.00% (37.50%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 5/48] [Loss: 0.651821 (1.389751), Acc: 62.50% (41.67%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 6/48] [Loss: 0.535276 (1.267683), Acc: 75.00% (46.43%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 16/20] [Batch 7/48] [Loss: 1.089023 (1.245351), Acc: 62.50% (48.44%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 16/20] [Batch 8/48] [Loss: 2.780327 (1.415904), Acc: 25.00% (45.83%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 9/48] [Loss: 1.107812 (1.385095), Acc: 75.00% (48.75%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 10/48] [Loss: 1.142610 (1.363050), Acc: 62.50% (50.00%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 16/20] [Batch 11/48] [Loss: 0.841301 (1.319571), Acc: 87.50% (53.12%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 16/20] [Batch 12/48] [Loss: 2.207067 (1.387840), Acc: 50.00% (52.88%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 16/20] [Batch 13/48] [Loss: 1.693403 (1.409666), Acc: 62.50% (53.57%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 16/20] [Batch 14/48] [Loss: 1.491109 (1.415096), Acc: 37.50% (52.50%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 15/48] [Loss: 0.842527 (1.379310), Acc: 62.50% (53.12%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 16/48] [Loss: 1.997633 (1.415682), Acc: 62.50% (53.68%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 17/48] [Loss: 0.868265 (1.385270), Acc: 50.00% (53.47%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 18/48] [Loss: 1.251201 (1.378214), Acc: 75.00% (54.61%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 19/48] [Loss: 0.233717 (1.320989), Acc: 87.50% (56.25%)]Min label: 1\n",
      "Max label: 8\n",
      "\\r[Epoch 16/20] [Batch 20/48] [Loss: 0.891401 (1.300532), Acc: 75.00% (57.14%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 16/20] [Batch 21/48] [Loss: 2.734217 (1.365700), Acc: 37.50% (56.25%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 22/48] [Loss: 1.350126 (1.365023), Acc: 62.50% (56.52%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 23/48] [Loss: 1.027754 (1.350970), Acc: 62.50% (56.77%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 16/20] [Batch 24/48] [Loss: 0.852086 (1.331014), Acc: 62.50% (57.00%)]Min label: 4\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 25/48] [Loss: 2.448310 (1.373987), Acc: 37.50% (56.25%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 26/48] [Loss: 0.928061 (1.357472), Acc: 75.00% (56.94%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 27/48] [Loss: 0.831087 (1.338672), Acc: 75.00% (57.59%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 16/20] [Batch 28/48] [Loss: 1.603718 (1.347812), Acc: 50.00% (57.33%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 29/48] [Loss: 2.132278 (1.373961), Acc: 25.00% (56.25%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 30/48] [Loss: 1.052622 (1.363595), Acc: 50.00% (56.05%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 16/20] [Batch 31/48] [Loss: 0.718423 (1.343433), Acc: 50.00% (55.86%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 32/48] [Loss: 2.025773 (1.364110), Acc: 50.00% (55.68%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 33/48] [Loss: 2.323738 (1.392335), Acc: 37.50% (55.15%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 34/48] [Loss: 0.967247 (1.380189), Acc: 75.00% (55.71%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 35/48] [Loss: 1.275921 (1.377293), Acc: 50.00% (55.56%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 36/48] [Loss: 1.395285 (1.377779), Acc: 62.50% (55.74%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 37/48] [Loss: 0.767794 (1.361727), Acc: 75.00% (56.25%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 38/48] [Loss: 0.883495 (1.349464), Acc: 62.50% (56.41%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 16/20] [Batch 39/48] [Loss: 0.860708 (1.337246), Acc: 50.00% (56.25%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 16/20] [Batch 40/48] [Loss: 1.922956 (1.351531), Acc: 25.00% (55.49%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 41/48] [Loss: 1.115736 (1.345917), Acc: 62.50% (55.65%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 16/20] [Batch 42/48] [Loss: 0.635497 (1.329396), Acc: 87.50% (56.40%)]Min label: 0\n",
      "Max label: 4\n",
      "\\r[Epoch 16/20] [Batch 43/48] [Loss: 0.767977 (1.316636), Acc: 62.50% (56.53%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 44/48] [Loss: 1.666606 (1.324413), Acc: 50.00% (56.39%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 16/20] [Batch 45/48] [Loss: 1.030871 (1.318032), Acc: 62.50% (56.52%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 16/20] [Batch 46/48] [Loss: 1.230494 (1.316169), Acc: 37.50% (56.12%)]Min label: 5\n",
      "Max label: 5\n",
      "\\r[Epoch 16/20] [Batch 47/48] [Loss: 1.944913 (1.329268), Acc: 50.00% (55.99%)]\n",
      "train , acc: 55.989583333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:34<00:00, 94.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 17 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 3\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 0/48] [Loss: 0.679238 (0.679238), Acc: 75.00% (75.00%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 17/20] [Batch 1/48] [Loss: 1.499328 (1.089283), Acc: 50.00% (62.50%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 17/20] [Batch 2/48] [Loss: 1.167634 (1.115400), Acc: 62.50% (62.50%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 17/20] [Batch 3/48] [Loss: 2.101424 (1.361906), Acc: 37.50% (56.25%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 17/20] [Batch 4/48] [Loss: 1.196248 (1.328774), Acc: 62.50% (57.50%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 17/20] [Batch 5/48] [Loss: 0.634364 (1.213039), Acc: 75.00% (60.42%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 17/20] [Batch 6/48] [Loss: 1.242476 (1.217245), Acc: 62.50% (60.71%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 17/20] [Batch 7/48] [Loss: 1.107763 (1.203559), Acc: 75.00% (62.50%)]Min label: 2\n",
      "Max label: 7\n",
      "\\r[Epoch 17/20] [Batch 8/48] [Loss: 1.107584 (1.192895), Acc: 62.50% (62.50%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 9/48] [Loss: 0.752194 (1.148825), Acc: 75.00% (63.75%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 17/20] [Batch 10/48] [Loss: 1.887529 (1.215980), Acc: 37.50% (61.36%)]Min label: 3\n",
      "Max label: 17\n",
      "\\r[Epoch 17/20] [Batch 11/48] [Loss: 2.777033 (1.346068), Acc: 25.00% (58.33%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 17/20] [Batch 12/48] [Loss: 1.031776 (1.321892), Acc: 62.50% (58.65%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 17/20] [Batch 13/48] [Loss: 0.486750 (1.262239), Acc: 75.00% (59.82%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 14/48] [Loss: 0.804552 (1.231726), Acc: 62.50% (60.00%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 17/20] [Batch 15/48] [Loss: 0.760558 (1.202278), Acc: 75.00% (60.94%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 16/48] [Loss: 0.666903 (1.170786), Acc: 62.50% (61.03%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 17/20] [Batch 17/48] [Loss: 0.592650 (1.138667), Acc: 75.00% (61.81%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 18/48] [Loss: 0.922051 (1.127266), Acc: 75.00% (62.50%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 17/20] [Batch 19/48] [Loss: 2.356695 (1.188737), Acc: 37.50% (61.25%)]Min label: 2\n",
      "Max label: 11\n",
      "\\r[Epoch 17/20] [Batch 20/48] [Loss: 0.816384 (1.171006), Acc: 75.00% (61.90%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 21/48] [Loss: 0.640015 (1.146870), Acc: 87.50% (63.07%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 17/20] [Batch 22/48] [Loss: 0.772795 (1.130606), Acc: 62.50% (63.04%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 23/48] [Loss: 1.001160 (1.125213), Acc: 50.00% (62.50%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 17/20] [Batch 24/48] [Loss: 0.507748 (1.100514), Acc: 100.00% (64.00%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 25/48] [Loss: 0.484285 (1.076813), Acc: 87.50% (64.90%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 26/48] [Loss: 1.552178 (1.094419), Acc: 50.00% (64.35%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 17/20] [Batch 27/48] [Loss: 1.133414 (1.095812), Acc: 62.50% (64.29%)]Min label: 2\n",
      "Max label: 17\n",
      "\\r[Epoch 17/20] [Batch 28/48] [Loss: 1.194045 (1.099199), Acc: 50.00% (63.79%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 29/48] [Loss: 0.600169 (1.082565), Acc: 87.50% (64.58%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 30/48] [Loss: 0.351650 (1.058987), Acc: 87.50% (65.32%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 17/20] [Batch 31/48] [Loss: 1.579772 (1.075261), Acc: 37.50% (64.45%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 17/20] [Batch 32/48] [Loss: 1.173298 (1.078232), Acc: 62.50% (64.39%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 17/20] [Batch 33/48] [Loss: 1.349197 (1.086202), Acc: 50.00% (63.97%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 34/48] [Loss: 0.570458 (1.071466), Acc: 87.50% (64.64%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 35/48] [Loss: 0.669125 (1.060290), Acc: 75.00% (64.93%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 17/20] [Batch 36/48] [Loss: 0.573127 (1.047123), Acc: 75.00% (65.20%)]Min label: 0\n",
      "Max label: 9\n",
      "\\r[Epoch 17/20] [Batch 37/48] [Loss: 1.415242 (1.056811), Acc: 62.50% (65.13%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 17/20] [Batch 38/48] [Loss: 0.505465 (1.042674), Acc: 87.50% (65.71%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 17/20] [Batch 39/48] [Loss: 0.809368 (1.036841), Acc: 62.50% (65.62%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 17/20] [Batch 40/48] [Loss: 0.883195 (1.033094), Acc: 62.50% (65.55%)]Min label: 2\n",
      "Max label: 10\n",
      "\\r[Epoch 17/20] [Batch 41/48] [Loss: 1.824418 (1.051935), Acc: 50.00% (65.18%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 17/20] [Batch 42/48] [Loss: 0.468740 (1.038372), Acc: 87.50% (65.70%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 43/48] [Loss: 0.409438 (1.024078), Acc: 87.50% (66.19%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 17/20] [Batch 44/48] [Loss: 1.774964 (1.040764), Acc: 37.50% (65.56%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 17/20] [Batch 45/48] [Loss: 1.414789 (1.048895), Acc: 37.50% (64.95%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 46/48] [Loss: 0.677946 (1.041003), Acc: 87.50% (65.43%)]Min label: 14\n",
      "Max label: 18\n",
      "\\r[Epoch 17/20] [Batch 47/48] [Loss: 7.192379 (1.169157), Acc: 0.00% (64.06%)]\n",
      "train , acc: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:34<00:00, 94.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 18 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 0/48] [Loss: 0.964926 (0.964926), Acc: 75.00% (75.00%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 18/20] [Batch 1/48] [Loss: 0.525887 (0.745407), Acc: 87.50% (81.25%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 2/48] [Loss: 1.550244 (1.013686), Acc: 50.00% (70.83%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 18/20] [Batch 3/48] [Loss: 0.969711 (1.002692), Acc: 75.00% (71.88%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 4/48] [Loss: 0.568609 (0.915876), Acc: 75.00% (72.50%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 5/48] [Loss: 0.506062 (0.847573), Acc: 75.00% (72.92%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 6/48] [Loss: 0.822189 (0.843947), Acc: 87.50% (75.00%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 7/48] [Loss: 1.248845 (0.894559), Acc: 62.50% (73.44%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 8/48] [Loss: 1.006909 (0.907042), Acc: 50.00% (70.83%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 18/20] [Batch 9/48] [Loss: 0.596934 (0.876032), Acc: 75.00% (71.25%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 10/48] [Loss: 1.128572 (0.898990), Acc: 75.00% (71.59%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 11/48] [Loss: 0.695003 (0.881991), Acc: 62.50% (70.83%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 12/48] [Loss: 0.245518 (0.833032), Acc: 100.00% (73.08%)]Min label: 1\n",
      "Max label: 13\n",
      "\\r[Epoch 18/20] [Batch 13/48] [Loss: 0.947064 (0.841177), Acc: 50.00% (71.43%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 18/20] [Batch 14/48] [Loss: 0.840039 (0.841101), Acc: 62.50% (70.83%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 18/20] [Batch 15/48] [Loss: 0.810794 (0.839207), Acc: 62.50% (70.31%)]Min label: 0\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 16/48] [Loss: 1.120219 (0.855737), Acc: 87.50% (71.32%)]Min label: 0\n",
      "Max label: 17\n",
      "\\r[Epoch 18/20] [Batch 17/48] [Loss: 1.657167 (0.900261), Acc: 37.50% (69.44%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 18/20] [Batch 18/48] [Loss: 0.960140 (0.903412), Acc: 50.00% (68.42%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 19/48] [Loss: 1.201104 (0.918297), Acc: 75.00% (68.75%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 20/48] [Loss: 0.553781 (0.900939), Acc: 75.00% (69.05%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 21/48] [Loss: 1.314271 (0.919727), Acc: 50.00% (68.18%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 18/20] [Batch 22/48] [Loss: 0.641786 (0.907642), Acc: 75.00% (68.48%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 23/48] [Loss: 1.757346 (0.943047), Acc: 37.50% (67.19%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 18/20] [Batch 24/48] [Loss: 0.766351 (0.935979), Acc: 62.50% (67.00%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 25/48] [Loss: 1.045755 (0.940201), Acc: 62.50% (66.83%)]Min label: 1\n",
      "Max label: 9\n",
      "\\r[Epoch 18/20] [Batch 26/48] [Loss: 1.193291 (0.949575), Acc: 62.50% (66.67%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 27/48] [Loss: 0.948329 (0.949530), Acc: 75.00% (66.96%)]Min label: 2\n",
      "Max label: 7\n",
      "\\r[Epoch 18/20] [Batch 28/48] [Loss: 1.361563 (0.963738), Acc: 62.50% (66.81%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 29/48] [Loss: 0.904707 (0.961771), Acc: 62.50% (66.67%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 30/48] [Loss: 0.831310 (0.957562), Acc: 75.00% (66.94%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 31/48] [Loss: 1.838700 (0.985098), Acc: 25.00% (65.62%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 32/48] [Loss: 0.892594 (0.982295), Acc: 62.50% (65.53%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 33/48] [Loss: 1.075260 (0.985029), Acc: 75.00% (65.81%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 34/48] [Loss: 0.644408 (0.975297), Acc: 75.00% (66.07%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 18/20] [Batch 35/48] [Loss: 0.878497 (0.972608), Acc: 75.00% (66.32%)]Min label: 3\n",
      "Max label: 8\n",
      "\\r[Epoch 18/20] [Batch 36/48] [Loss: 1.100573 (0.976066), Acc: 50.00% (65.88%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 18/20] [Batch 37/48] [Loss: 1.292624 (0.984397), Acc: 50.00% (65.46%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 18/20] [Batch 38/48] [Loss: 1.053909 (0.986179), Acc: 62.50% (65.38%)]Min label: 3\n",
      "Max label: 12\n",
      "\\r[Epoch 18/20] [Batch 39/48] [Loss: 0.899161 (0.984004), Acc: 62.50% (65.31%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 18/20] [Batch 40/48] [Loss: 0.887961 (0.981661), Acc: 62.50% (65.24%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 41/48] [Loss: 0.915769 (0.980092), Acc: 62.50% (65.18%)]Min label: 2\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 42/48] [Loss: 0.866951 (0.977461), Acc: 62.50% (65.12%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 18/20] [Batch 43/48] [Loss: 1.125815 (0.980833), Acc: 62.50% (65.06%)]Min label: 2\n",
      "Max label: 14\n",
      "\\r[Epoch 18/20] [Batch 44/48] [Loss: 1.186350 (0.985400), Acc: 50.00% (64.72%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 45/48] [Loss: 0.652780 (0.978169), Acc: 75.00% (64.95%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 18/20] [Batch 46/48] [Loss: 1.258080 (0.984125), Acc: 37.50% (64.36%)]Min label: 2\n",
      "Max label: 2\n",
      "\\r[Epoch 18/20] [Batch 47/48] [Loss: 2.080525 (1.006966), Acc: 0.00% (63.02%)]\n",
      "train , acc: 63.020833333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:33<00:00, 93.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 19 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase train ---\n",
      "Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 19/20] [Batch 0/48] [Loss: 1.175706 (1.175706), Acc: 50.00% (50.00%)]Min label: 3\n",
      "Max label: 15\n",
      "\\r[Epoch 19/20] [Batch 1/48] [Loss: 1.656593 (1.416150), Acc: 37.50% (43.75%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 2/48] [Loss: 0.424914 (1.085738), Acc: 87.50% (58.33%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 3/48] [Loss: 0.249340 (0.876638), Acc: 87.50% (65.62%)]Min label: 1\n",
      "Max label: 17\n",
      "\\r[Epoch 19/20] [Batch 4/48] [Loss: 0.748298 (0.850970), Acc: 75.00% (67.50%)]Min label: 2\n",
      "Max label: 12\n",
      "\\r[Epoch 19/20] [Batch 5/48] [Loss: 0.607309 (0.810360), Acc: 75.00% (68.75%)]Min label: 0\n",
      "Max label: 12\n",
      "\\r[Epoch 19/20] [Batch 6/48] [Loss: 0.701953 (0.794873), Acc: 62.50% (67.86%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 7/48] [Loss: 0.696588 (0.782588), Acc: 87.50% (70.31%)]Min label: 1\n",
      "Max label: 12\n",
      "\\r[Epoch 19/20] [Batch 8/48] [Loss: 0.665768 (0.769608), Acc: 62.50% (69.44%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 9/48] [Loss: 0.875992 (0.780246), Acc: 62.50% (68.75%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 10/48] [Loss: 0.783285 (0.780522), Acc: 75.00% (69.32%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 19/20] [Batch 11/48] [Loss: 1.338557 (0.827025), Acc: 75.00% (69.79%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 12/48] [Loss: 1.056001 (0.844639), Acc: 75.00% (70.19%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 19/20] [Batch 13/48] [Loss: 1.468051 (0.889168), Acc: 50.00% (68.75%)]Min label: 1\n",
      "Max label: 11\n",
      "\\r[Epoch 19/20] [Batch 14/48] [Loss: 0.833972 (0.885489), Acc: 75.00% (69.17%)]Min label: 2\n",
      "Max label: 8\n",
      "\\r[Epoch 19/20] [Batch 15/48] [Loss: 0.686374 (0.873044), Acc: 75.00% (69.53%)]Min label: 4\n",
      "Max label: 17\n",
      "\\r[Epoch 19/20] [Batch 16/48] [Loss: 1.193530 (0.891896), Acc: 62.50% (69.12%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 17/48] [Loss: 0.677474 (0.879984), Acc: 75.00% (69.44%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 19/20] [Batch 18/48] [Loss: 0.299362 (0.849425), Acc: 87.50% (70.39%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 19/20] [Batch 19/48] [Loss: 0.751268 (0.844517), Acc: 87.50% (71.25%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 20/48] [Loss: 0.574190 (0.831644), Acc: 75.00% (71.43%)]Min label: 2\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 21/48] [Loss: 0.920998 (0.835706), Acc: 62.50% (71.02%)]Min label: 0\n",
      "Max label: 5\n",
      "\\r[Epoch 19/20] [Batch 22/48] [Loss: 0.473366 (0.819952), Acc: 75.00% (71.20%)]Min label: 2\n",
      "Max label: 10\n",
      "\\r[Epoch 19/20] [Batch 23/48] [Loss: 1.691709 (0.856275), Acc: 37.50% (69.79%)]Min label: 2\n",
      "Max label: 5\n",
      "\\r[Epoch 19/20] [Batch 24/48] [Loss: 0.816907 (0.854700), Acc: 62.50% (69.50%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 19/20] [Batch 25/48] [Loss: 0.828350 (0.853687), Acc: 75.00% (69.71%)]Min label: 3\n",
      "Max label: 11\n",
      "\\r[Epoch 19/20] [Batch 26/48] [Loss: 0.632067 (0.845479), Acc: 75.00% (69.91%)]Min label: 0\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 27/48] [Loss: 0.907273 (0.847685), Acc: 75.00% (70.09%)]Min label: 1\n",
      "Max label: 9\n",
      "\\r[Epoch 19/20] [Batch 28/48] [Loss: 1.570201 (0.872600), Acc: 50.00% (69.40%)]Min label: 3\n",
      "Max label: 14\n",
      "\\r[Epoch 19/20] [Batch 29/48] [Loss: 0.326088 (0.854383), Acc: 100.00% (70.42%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 19/20] [Batch 30/48] [Loss: 0.410294 (0.840057), Acc: 87.50% (70.97%)]Min label: 3\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 31/48] [Loss: 1.789819 (0.869737), Acc: 50.00% (70.31%)]Min label: 3\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 32/48] [Loss: 1.585467 (0.891426), Acc: 75.00% (70.45%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 33/48] [Loss: 1.316055 (0.903915), Acc: 75.00% (70.59%)]Min label: 2\n",
      "Max label: 15\n",
      "\\r[Epoch 19/20] [Batch 34/48] [Loss: 0.670550 (0.897248), Acc: 75.00% (70.71%)]Min label: 0\n",
      "Max label: 15\n",
      "\\r[Epoch 19/20] [Batch 35/48] [Loss: 1.146151 (0.904162), Acc: 50.00% (70.14%)]Min label: 1\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 36/48] [Loss: 0.760947 (0.900291), Acc: 62.50% (69.93%)]Min label: 1\n",
      "Max label: 14\n",
      "\\r[Epoch 19/20] [Batch 37/48] [Loss: 1.115746 (0.905961), Acc: 62.50% (69.74%)]Min label: 0\n",
      "Max label: 7\n",
      "\\r[Epoch 19/20] [Batch 38/48] [Loss: 1.522327 (0.921765), Acc: 62.50% (69.55%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 19/20] [Batch 39/48] [Loss: 1.048124 (0.924924), Acc: 62.50% (69.38%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 40/48] [Loss: 1.406926 (0.936680), Acc: 75.00% (69.51%)]Min label: 1\n",
      "Max label: 15\n",
      "\\r[Epoch 19/20] [Batch 41/48] [Loss: 2.330633 (0.969870), Acc: 62.50% (69.35%)]Min label: 1\n",
      "Max label: 5\n",
      "\\r[Epoch 19/20] [Batch 42/48] [Loss: 1.341290 (0.978507), Acc: 50.00% (68.90%)]Min label: 2\n",
      "Max label: 6\n",
      "\\r[Epoch 19/20] [Batch 43/48] [Loss: 1.131844 (0.981992), Acc: 50.00% (68.47%)]Min label: 1\n",
      "Max label: 18\n",
      "\\r[Epoch 19/20] [Batch 44/48] [Loss: 0.377370 (0.968556), Acc: 100.00% (69.17%)]Min label: 2\n",
      "Max label: 13\n",
      "\\r[Epoch 19/20] [Batch 45/48] [Loss: 0.544720 (0.959342), Acc: 87.50% (69.57%)]Min label: 0\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 46/48] [Loss: 1.337271 (0.967383), Acc: 62.50% (69.41%)]Min label: 5\n",
      "Max label: 16\n",
      "\\r[Epoch 19/20] [Batch 47/48] [Loss: 3.165364 (1.013175), Acc: 0.00% (67.97%)]\n",
      "train , acc: 67.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:34<00:00, 94.19s/it]\n"
     ]
    }
   ],
   "source": [
    "#БЫЛ ПЕРВЫЙ ПРОГОН НА ЭТОМ КОДЕ\n",
    "# os.makedirs('/root/akhsup/weights', exist_ok=True)\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Для отладки\n",
    "# from torch.autograd import Variable\n",
    "# iteration = 0\n",
    "# # acc_all = list()\n",
    "# loss_all = list()\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print('')\n",
    "#     print(f\"--- Epoch {epoch} ---\")\n",
    "#     phase1 = dataloaders.keys()\n",
    "#     for phase in tqdm(phase1):\n",
    "#         print('')\n",
    "#         print(f\"--- Phase {phase} ---\")\n",
    "#         epoch_metrics = {\"loss\": [], \"acc\": []}\n",
    "#         for batch_i, (X, y) in enumerate(dataloaders[phase]):\n",
    "#             # Перемещаем данные на устройство (GPU)\n",
    "#             image_sequences = Variable(X.to(device), requires_grad=True)\n",
    "#             labels = Variable(y.to(device), requires_grad=False)\n",
    "            \n",
    "# #             print(\"Min label:\", torch.min(labels).item())\n",
    "# #             print(\"Max label:\", torch.max(labels).item())\n",
    "# #             assert torch.min(labels) >= 0 and torch.max(labels) < 19, \"Метки классов выходят за пределы допустимого диапазона!\"\n",
    "            \n",
    "# #             if torch.isnan(image_sequences).any() or torch.isinf(image_sequences).any():\n",
    "# #                 print(\"Найдены NaN или Inf в данных!\")\n",
    "# #                 continue\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             predictions = model(image_sequences)\n",
    "            \n",
    "# #             if torch.isnan(predictions).any() or torch.isinf(predictions).any():\n",
    "# #                 print(\"Найдены NaN или Inf в выходе модели!\")\n",
    "# #                 continue\n",
    "            \n",
    "#             loss = cls_criterion(predictions, labels)\n",
    "#             acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             epoch_metrics[\"loss\"].append(loss.item())\n",
    "#             epoch_metrics[\"acc\"].append(acc)\n",
    "            \n",
    "#             if phase == 'train':\n",
    "#                 lr, mom = onecyc.calc()\n",
    "#                 update_lr(optimizer, lr)\n",
    "#                 update_mom(optimizer, mom)\n",
    "            \n",
    "#             batches_done = epoch * len(dataloaders[phase]) + batch_i\n",
    "#             batches_left = num_epochs * len(dataloaders[phase]) - batches_done\n",
    "#             sys.stdout.write(\n",
    "#                 \"\\\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)]\"\n",
    "#                 % (\n",
    "#                     epoch,\n",
    "#                     num_epochs,\n",
    "#                     batch_i,\n",
    "#                     len(dataloaders[phase]),\n",
    "#                     loss.item(),\n",
    "#                     np.mean(epoch_metrics[\"loss\"]),\n",
    "#                     acc,\n",
    "#                     np.mean(epoch_metrics[\"acc\"]),\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#             if torch.cuda.is_available():\n",
    "#                 torch.cuda.empty_cache()\n",
    "\n",
    "#         print('')\n",
    "#         print('{} , acc: {}'.format(phase, np.mean(epoch_metrics[\"acc\"])))\n",
    "#         torch.save(model.state_dict(), '/root/akhsup/res/data.txt'.format(epoch))\n",
    "#         if phase == 'train':\n",
    "#             acc_all.append(np.mean(epoch_metrics[\"acc\"]))\n",
    "#             loss_all.append(np.mean(epoch_metrics[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25137be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:43,  2.15s/it]\n",
      "10it [00:20,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.6855, Val_loss: 65.3912, Precision: 0.1157, Recall: 0.2785, F1: 0.1612\n",
      "\n",
      "--- Epoch 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:37,  2.04s/it]\n",
      "10it [00:19,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.6410, Val_loss: 3.8591, Precision: 0.1792, Recall: 0.2278, F1: 0.1901\n",
      "\n",
      "--- Epoch 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:36,  2.02s/it]\n",
      "10it [00:19,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.6023, Val_loss: 2.4220, Precision: 0.1760, Recall: 0.3038, F1: 0.2116\n",
      "\n",
      "--- Epoch 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:39,  2.07s/it]\n",
      "10it [00:20,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.6003, Val_loss: 2.1498, Precision: 0.2019, Recall: 0.2911, F1: 0.2326\n",
      "\n",
      "--- Epoch 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:36,  2.02s/it]\n",
      "10it [00:19,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.5035, Val_loss: 2.0964, Precision: 0.2764, Recall: 0.4557, F1: 0.3300\n",
      "\n",
      "--- Epoch 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:39,  2.07s/it]\n",
      "10it [00:19,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.4698, Val_loss: 2.0740, Precision: 0.2466, Recall: 0.3418, F1: 0.2723\n",
      "\n",
      "--- Epoch 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:54,  2.38s/it]\n",
      "10it [00:20,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.4280, Val_loss: 1.9892, Precision: 0.2316, Recall: 0.3038, F1: 0.2426\n",
      "\n",
      "--- Epoch 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:37,  2.03s/it]\n",
      "10it [00:20,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.4173, Val_loss: 3.6172, Precision: 0.1321, Recall: 0.2785, F1: 0.1739\n",
      "\n",
      "--- Epoch 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:39,  2.08s/it]\n",
      "10it [00:20,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.4288, Val_loss: 2.0961, Precision: 0.2880, Recall: 0.4430, F1: 0.3292\n",
      "\n",
      "--- Epoch 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:37,  2.03s/it]\n",
      "10it [00:20,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.1298, Val_loss: 1.9297, Precision: 0.3571, Recall: 0.3165, F1: 0.2943\n",
      "\n",
      "--- Epoch 11 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:36,  2.02s/it]\n",
      "10it [00:19,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.1147, Val_loss: 1.7433, Precision: 0.3899, Recall: 0.4304, F1: 0.3913\n",
      "\n",
      "--- Epoch 12 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:38,  2.05s/it]\n",
      "10it [00:20,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.0902, Val_loss: 1.7476, Precision: 0.4574, Recall: 0.3544, F1: 0.3323\n",
      "\n",
      "--- Epoch 13 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:37,  2.03s/it]\n",
      "10it [00:19,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 2.0066, Val_loss: 1.4516, Precision: 0.3391, Recall: 0.4177, F1: 0.3637\n",
      "\n",
      "--- Epoch 14 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:40,  2.09s/it]\n",
      "10it [00:20,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.7505, Val_loss: 1.6653, Precision: 0.3179, Recall: 0.3671, F1: 0.3296\n",
      "\n",
      "--- Epoch 15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:38,  2.05s/it]\n",
      "10it [00:20,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.8837, Val_loss: 1.4327, Precision: 0.4706, Recall: 0.5443, F1: 0.4846\n",
      "\n",
      "--- Epoch 16 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:38,  2.05s/it]\n",
      "10it [00:20,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.7939, Val_loss: 1.5954, Precision: 0.3680, Recall: 0.4177, F1: 0.3639\n",
      "\n",
      "--- Epoch 17 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:37,  2.02s/it]\n",
      "10it [00:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.7613, Val_loss: 1.1609, Precision: 0.3662, Recall: 0.5949, F1: 0.4510\n",
      "\n",
      "--- Epoch 18 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:37,  2.03s/it]\n",
      "10it [00:19,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.4146, Val_loss: 1.3356, Precision: 0.4345, Recall: 0.4557, F1: 0.3942\n",
      "\n",
      "--- Epoch 19 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [01:34,  1.97s/it]\n",
      "10it [00:19,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.5187, Val_loss: 1.0230, Precision: 0.5884, Recall: 0.6962, F1: 0.6200\n",
      "\n",
      "--- Epoch 20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:35,  2.00s/it]\n",
      "10it [00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 1.3856, Val_loss: 1.0356, Precision: 0.5970, Recall: 0.6709, F1: 0.5832\n",
      "Best F1-score: 0.6200 in epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs('/root/akhsup/weights', exist_ok=True)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "iteration = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "train_loss = 0.0\n",
    "val_loss = 0.0\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('')\n",
    "    print(f\"--- Epoch {epoch+1} ---\")\n",
    "    \n",
    "    for phase in dataloaders.keys():\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for batch_i, (X, y) in tqdm(enumerate(dataloaders[phase])):\n",
    "            image_sequences = X.to(device)\n",
    "            labels = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                predictions = model(image_sequences)\n",
    "                loss = cls_criterion(predictions, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * image_sequences.size(0)\n",
    "            _, preds = torch.max(predictions, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            if phase == 'train':\n",
    "                lr, mom = onecyc.calc()\n",
    "                update_lr(optimizer, lr)\n",
    "                update_mom(optimizer, mom)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_loss = epoch_loss / len(dataloaders[phase].dataset)\n",
    "\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "        if phase == 'train':\n",
    "            train_losses.append(epoch_loss)\n",
    "            train_loss = epoch_loss\n",
    "        else:\n",
    "            val_losses.append(epoch_loss)\n",
    "            val_loss = epoch_loss\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_epoch = epoch+1\n",
    "                torch.save(model.state_dict(), f'/root/akhsup/weights/best_model_f1_{best_epoch}.pth')\n",
    "\n",
    "    print(f\"Train_loss: {train_loss:.4f}, Val_loss: {val_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "#     torch.save(model.state_dict(), f'/root/akhsup/weights/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "print(f\"Best F1-score: {best_f1:.4f} in epochs {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "526204b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss (try 1)')\n",
    "plt.legend()\n",
    "plt.savefig('/root/akhsup/weights/loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ae790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, num_classes=19):\n",
    "    model = resnet200(class_num=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_video(video_path, sequence_length=10, im_size=128):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((im_size, im_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4889, 0.4887, 0.4891], std=[0.2074, 0.2074, 0.2074])\n",
    "    ])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while len(frames) < sequence_length:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = transform(frame) \n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(f\"Ошибка: Видео '{video_path}' не содержит кадров или файл повреждён.\")\n",
    "\n",
    "    while len(frames) < sequence_length:\n",
    "        frames.append(torch.zeros_like(frames[-1]))\n",
    "\n",
    "    video_tensor = torch.stack(frames)  # (sequence_length, channels, height, width)\n",
    "    video_tensor = video_tensor.permute(1, 0, 2, 3)  # (channels, sequence_length, height, width)\n",
    "    return video_tensor.unsqueeze(0)  # Добавляем batch dimension: (1, channels, sequence_length, height, width)\n",
    "\n",
    "def predict_video(model, video_tensor, device):\n",
    "    with torch.no_grad():\n",
    "        video_tensor = video_tensor.to(device)\n",
    "        outputs = model(video_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "def test_video(model_path, video_path, encoder, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model = load_model(model_path)\n",
    "    model = model.to(device)\n",
    "\n",
    "    video_tensor = preprocess_video(video_path)\n",
    "\n",
    "    predicted_class = predict_video(model, video_tensor, device)\n",
    "    \n",
    "    predicted_label = encoder.get(predicted_class, \"Unknown class\")\n",
    "#     print(f\"Name of Predicted class: {predicted_label}\")\n",
    "\n",
    "#     print(f\"Number of predicted class: {predicted_class}\")\n",
    "    return predicted_class\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "#     video_path = \"/root/akhsup/test/test.mp4\"\n",
    "#     test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d05a3e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762807/2322475451.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Predicted class: measure\n",
      "Number of predicted class: 3\n"
     ]
    }
   ],
   "source": [
    "#верно (с валидации)\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "video_path = \"/root/tatneft/datasets/violations_dataset/cuts1/ch03_20231002080315_cut_002613_002618.mp4\"\n",
    "test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cf0d116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762807/2322475451.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Predicted class: syringing\n",
      "Number of predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "#неверно долнжо быть 0 (с валидации)\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "video_path = \"/root/tatneft/datasets/violations_dataset/cuts1/ch03_20231002080000_cut_000036_000041.mp4\"\n",
    "test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be4eb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762807/2322475451.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Predicted class: syringing\n",
      "Number of predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "#верно (с валидации)\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "video_path = \"/root/tatneft/datasets/violations_dataset/cuts1/ch03_20231002080315_cut_001021_001026.mp4\"\n",
    "test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43dd603e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762807/2322475451.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Predicted class: pipe_work\n",
      "Number of predicted class: 4\n"
     ]
    }
   ],
   "source": [
    "#верно (с валидации)\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "video_path = \"/root/tatneft/datasets/violations_dataset/cuts1/ch03_20231002080315_cut_004400_004405.mp4\"\n",
    "test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "838fef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762807/2322475451.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Predicted class: HRW_work\n",
      "Number of predicted class: 5\n"
     ]
    }
   ],
   "source": [
    "#верно (с валидации)\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "video_path = \"/root/tatneft/datasets/violations_dataset/cuts1/ch03_20231002080315_cut_005031_005036.mp4\"\n",
    "test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b02643bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762807/2322475451.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Predicted class: HRW_work\n",
      "Number of predicted class: 5\n"
     ]
    }
   ],
   "source": [
    "#неверно должен быть 7 (с валидации)\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "video_path = \"/root/tatneft/datasets/violations_dataset/cuts1/ch03_20231002080315_cut_005304_005309.mp4\"\n",
    "test_video(model_path, video_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ed4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "df = pd.DataFrame(columns=['video', 'prediction', 'label', 'duration'])\n",
    "model_path = \"/root/akhsup/weights/best_model_f1_19.pth\"\n",
    "val_labels = []\n",
    "with open('/root/tatneft/datasets/violations_dataset/cuts1_val.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            video_file, label = line.strip().split()\n",
    "            val_labels.append((video_file, int(label)))\n",
    "\n",
    "for video, label in val_labels:\n",
    "    video_path = '/root/tatneft/datasets/violations_dataset/cuts1/' + video\n",
    "    predict = test_video(model_path, video_path, encoder)\n",
    "    clip = VideoFileClip(video_path)\n",
    "    new_row = {\n",
    "        'video': video,\n",
    "        'prediction': predict,\n",
    "        'label': label, \n",
    "        'duration': clip.duration\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "836f41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('results.xlsx', sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b7ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tatneft",
   "language": "python",
   "name": "tatneft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06b8a0459549421395de7718536417df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "235d7ce842f247a09ae3a55ff2071f8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3907e592cb9c445c845733a557ae1720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db1c0c82310a4e01961a90095f4f29b4",
      "placeholder": "​",
      "style": "IPY_MODEL_06b8a0459549421395de7718536417df",
      "value": " 2/465 [00:00&lt;00:04, 93.07it/s]"
     }
    },
    "4554afe822fb48a4af582d76276a7d24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6645df8386b9451baa975f7b1cdaf07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7301625c753d4f2d906ac5810512c5ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4554afe822fb48a4af582d76276a7d24",
      "max": 465,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6645df8386b9451baa975f7b1cdaf07d",
      "value": 2
     }
    },
    "a883fb8a46844925943690fad81370bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa7b09bbf6d640e5bd5b67f943206dfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7e1735e2f734d209e0210bddbae583b",
       "IPY_MODEL_7301625c753d4f2d906ac5810512c5ae",
       "IPY_MODEL_3907e592cb9c445c845733a557ae1720"
      ],
      "layout": "IPY_MODEL_235d7ce842f247a09ae3a55ff2071f8e"
     }
    },
    "db1c0c82310a4e01961a90095f4f29b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e734a380e7f142e6bdd5d3f8d218c0d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7e1735e2f734d209e0210bddbae583b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e734a380e7f142e6bdd5d3f8d218c0d9",
      "placeholder": "​",
      "style": "IPY_MODEL_a883fb8a46844925943690fad81370bc",
      "value": "  0%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
